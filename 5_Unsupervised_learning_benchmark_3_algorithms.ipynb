{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_INFORMATION-->\n",
    "<img id=\"r-1060983\" data-claire-element-id=\"1061343\" src=\"http://www.siteduzero.com/favicon.ico\" alt=\"Image utilisateur\">\n",
    "    <p>\n",
    "        **<font color='#D2691E'size=\"6\">Tags recommendation (6/7)</font>**.\n",
    "    </p>\n",
    "\n",
    "<p>\n",
    "    This notebook's goal is to compare the performances of the 3 unsupervised approaches (NMF, LDA and LDA+Word2Vec) used in this project.\n",
    "</p>\n",
    "<p>\n",
    "    It is called in the notebook \"6_Workflows_iteration.ipynb\" in order to loop over it's hyperparameters\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <center>\n",
    "        **<font color='\t#D2691E'size=\"6\">PLAN</font>**\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">0) Libraries, functions and datasources import</font>**\n",
    "</p>\n",
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">I) Starting the program</font>**\n",
    "</p>\n",
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">II) Evaluation & Benchmark of the algorithms performances</font>**\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library, functions and datasources import\n"
     ]
    }
   ],
   "source": [
    "print(\"Library, functions and datasources import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context import dir_path, datasources_path, enrichment_path, pickles_path, temp_files_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import aggregate_col_in_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model = pickle.load(open(pickles_path+\"df_model_unsupervised.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_indexes = pickle.load(open(pickles_path+\"L_train_indexes.p\", \"rb\" ))\n",
    "L_test_indexes = pickle.load(open(pickles_path+\"L_test_indexes.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_frequent_tags = pickle.load(open(pickles_path+\"L_frequent_tags.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_model[df_model['id'].isin(L_train_indexes)]\n",
    "df_test = df_model[df_model['id'].isin(L_test_indexes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_nmf = df_model[df_model['id'].isin(L_train_indexes)]\n",
    "df_test_nmf = df_model[df_model['id'].isin(L_test_indexes)]\n",
    "\n",
    "df_train_lda = df_model[df_model['id'].isin(L_train_indexes)]\n",
    "df_test_lda = df_model[df_model['id'].isin(L_test_indexes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_corpus = list(df_train_nmf['corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_params_workflows_iteration = pickle.load(open(pickles_path+\"execution_params_workflows_iteration.p\", \"rb\" ))\n",
    "RUN = execution_params_workflows_iteration['RUN']\n",
    "N_COMPONENTS = execution_params_workflows_iteration['N_COMPONENTS']\n",
    "TOPICS_THRESHOLD = execution_params_workflows_iteration['TOPICS_THRESHOLD']\n",
    "NEIGHBORS = execution_params_workflows_iteration['NEIGHBORS']\n",
    "QUANTILE_THRESHOLD = execution_params_workflows_iteration['QUANTILE_THRESHOLD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">I) Starting the program</font>**\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Starting run 1 with params :\n",
      "N_COMPONENTS = 10 \n",
      "THRESHOLD = 10\n",
      "NEIGHBORS = 5\n",
      "QUANTILE_THRESHOLD = 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\\nStarting run %s with params :\\nN_COMPONENTS = %s \\nTHRESHOLD = %s\\nNEIGHBORS = %s\\nQUANTILE_THRESHOLD = %s\"%(RUN,N_COMPONENTS,TOPICS_THRESHOLD,NEIGHBORS,QUANTILE_THRESHOLD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implementing NMF\n"
     ]
    }
   ],
   "source": [
    "print(\"implementing NMF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 1000\n",
    "N_TOP_WORDS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "--- 0.11967873573303223 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Use count (raw term count) features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=10,max_features=N_FEATURES)\n",
    "start_time = time.time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(L_corpus)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model\n",
      "--- 0.1795194149017334 seconds ---\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the NMF model\")\n",
    "start_time = time.time()\n",
    "nmf = NMF(n_components=N_COMPONENTS, random_state=0,alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "vectorizer_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_words_space_schema built!\n"
     ]
    }
   ],
   "source": [
    "df_train_nmf_words_space_schema = pd.DataFrame(columns = vectorizer_feature_names)\n",
    "df_train_nmf_words_space_schema\n",
    "print(\"train_words_space_schema built!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implementing LDA\n"
     ]
    }
   ],
   "source": [
    "print(\"implementing LDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting count features for LDA...\n",
      "--- 0.12566018104553223 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting count features for LDA...\")\n",
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=10, max_features=N_FEATURES)\n",
    "start_time = time.time()\n",
    "count = count_vectorizer.fit_transform(L_corpus)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the LDA model\n",
      "--- 4.556853294372559 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the LDA model\")\n",
    "lda = LatentDirichletAllocation(n_components=N_COMPONENTS, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "start_time = time.time()\n",
    "lda.fit(count)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_nmf = nmf.transform(tfidf)\n",
    "results_lda = lda.transform(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_main_topics_nmf = []\n",
    "L_main_topics_lda = []\n",
    "for sub_result_nmf,sub_result_lda in zip(results_nmf,results_lda):\n",
    "    L_main_topics_nmf.append(np.argmax(sub_result_nmf))\n",
    "    L_main_topics_lda.append(np.argmax(sub_result_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_corpus_topics_nmf = pd.DataFrame(results_nmf)\n",
    "df_corpus_topics_lda = pd.DataFrame(results_lda)\n",
    "\n",
    "df_corpus_topics_nmf['id'] = list(df_train_nmf['id'])\n",
    "df_corpus_topics_lda['id'] = list(df_train_lda['id'])\n",
    "\n",
    "df_corpus_topics_nmf['main_topic'] = L_main_topics_nmf\n",
    "df_corpus_topics_lda['main_topic'] = L_main_topics_lda\n",
    "\n",
    "df_corpus_topics_nmf['corpus'] = L_corpus\n",
    "df_corpus_topics_lda['corpus'] = L_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_topics = []\n",
    "for topic in range(N_COMPONENTS):\n",
    "    L_topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics associated to words management\n"
     ]
    }
   ],
   "source": [
    "print(\"Topics associated to words management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_topics_words_nmf = pd.DataFrame(nmf.components_, columns=vectorizer_feature_names)\n",
    "df_topics_words_lda = pd.DataFrame(lda.components_, columns=vectorizer_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words/topics normalization\n"
     ]
    }
   ],
   "source": [
    "print(\"words/topics normalization\")\n",
    "for column in df_topics_words_nmf.columns:\n",
    "    column_sum = np.sum(df_topics_words_nmf[column])\n",
    "    df_topics_words_nmf[column] = df_topics_words_nmf[column].apply(lambda x : x/column_sum)\n",
    "    column_sum = np.sum(df_topics_words_lda[column])\n",
    "    df_topics_words_lda[column] = df_topics_words_lda[column].apply(lambda x : x/column_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words associated to Topics management\n"
     ]
    }
   ],
   "source": [
    "print(\"Words associated to Topics management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_words_topics_nmf = df_topics_words_nmf.T\n",
    "df_words_topics_lda = df_topics_words_lda.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models has 119 tags coordinates in the topics space | 146 tags are missing\n"
     ]
    }
   ],
   "source": [
    "L_matching_tags = [word for word in df_words_topics_nmf.index if word in L_frequent_tags]\n",
    "L_missing_tags = [word for word in L_frequent_tags if not word in L_matching_tags]\n",
    "\n",
    "print(\"The models has %s tags coordinates in the topics space | %s tags are missing\"%(len(L_matching_tags),len(L_missing_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags associated to topics management\n"
     ]
    }
   ],
   "source": [
    "print(\"Tags associated to topics management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developping the train dataframe\n",
      "Multiprocessing\n",
      "Creating pool with 6 processes\n",
      "\n",
      "df_append\n",
      "df_append\n",
      "df_append\n",
      "df_append\n",
      "df_append\n",
      "df_append\n",
      "--- 4.623292446136475 seconds ---\n",
      "the result file is available at : \n",
      " temp_files_path+\"developped_dataframe.p\"\n",
      "train dataframe developped\n"
     ]
    }
   ],
   "source": [
    "print(\"Developping the train dataframe\")\n",
    "#We want to denormalize our entry dataframe thanks to the 'tag_list' column :\n",
    "#We specify the excution params for  the python script responsible for the multiprocessing : \n",
    "execution_params = {'N_PROCS' : 6,\n",
    "                    'dataframe':df_train[['tag_list','id']],\n",
    "                   'column_to_develop':'tag_list'}\n",
    "#We dump our execution params :\n",
    "pickle.dump(execution_params,open(temp_files_path+\"execution_params.p\", \"wb\"))\n",
    "#And we run the script responsible for the stopwords elimination on different process :  \n",
    "%run -i multiprocessing_develop.py\n",
    "\n",
    "\n",
    "#We load the result of the multiprocessing task : \n",
    "developped_dataframe = pickle.load(open(temp_files_path+\"developped_dataframe.p\", \"rb\" ))\n",
    "\n",
    "#We clean the temp files dir :\n",
    "import os\n",
    "from functions import class_my_files\n",
    "dict_extensions = class_my_files(temp_files_path)\n",
    "pickles_temp_files  = dict_extensions['p']\n",
    "for file_name in pickles_temp_files:\n",
    "    os.remove(temp_files_path+file_name)\n",
    "\n",
    "developped_dataframe.sort_values(by='id', inplace=True)\n",
    "developped_dataframe.rename({'tag_list':'tag'}, axis=1, inplace=True)\n",
    "print(\"train dataframe developped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join between the developped dataframe and the NMF and LDA corpus/topics distributions dataframes\n"
     ]
    }
   ],
   "source": [
    "print(\"Join between the developped dataframe and the NMF and LDA corpus/topics distributions dataframes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the dataframe is denormalized on the 'tag' column, we can compute the average topic distribution for each tag :\n",
    "global_df_corpus_topics_nmf = pd.merge(developped_dataframe,df_corpus_topics_nmf,how='left',on='id')\n",
    "global_df_corpus_topics_lda = pd.merge(developped_dataframe,df_corpus_topics_lda,how='left',on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation\n"
     ]
    }
   ],
   "source": [
    "print(\"Aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We first parameter the list  of columns we need for the aggregation :\n",
    "L_tags_topics = L_topics.copy()\n",
    "L_tags_topics.append('tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#And we aggregate the topics distributions by the dataframe's tags\n",
    "df_tags_topics_nmf = global_df_corpus_topics_nmf[L_tags_topics].groupby('tag').mean()\n",
    "df_tags_topics_lda = global_df_corpus_topics_lda[L_tags_topics].groupby('tag').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words/topics normalization\n"
     ]
    }
   ],
   "source": [
    "print(\"words/topics normalization\")\n",
    "for tag in df_tags_topics_nmf.index:\n",
    "    row_sum = np.sum(df_tags_topics_nmf.loc[tag,])\n",
    "    df_tags_topics_nmf.loc[tag,] = df_tags_topics_nmf.loc[tag,]/row_sum\n",
    "    row_sum = np.sum(df_tags_topics_lda.loc[tag,])\n",
    "    df_tags_topics_lda.loc[tag,] = df_tags_topics_lda.loc[tag,]/row_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Finally, the dataframe mapping all tags to their topics distribution is :\n",
    "df_tags_topics_nmf = df_tags_topics_nmf.loc[L_missing_tags,].append(df_words_topics_nmf.loc[L_matching_tags,])\n",
    "df_tags_topics_lda = df_tags_topics_lda.loc[L_missing_tags,].append(df_words_topics_lda.loc[L_matching_tags,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#And we can now append the missing tags in the dataframe which maps all words to their topics : \n",
    "df_words_topics_nmf = df_words_topics_nmf.append(df_tags_topics_nmf.loc[L_missing_tags,])\n",
    "df_words_topics_lda = df_words_topics_lda.append(df_tags_topics_lda.loc[L_missing_tags,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the NMF word/tags similatities matrices\n"
     ]
    }
   ],
   "source": [
    "print(\"Building the NMF word/tags similatities matrices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With this two dataframes, we can compute the similarities between tags and words (with tags) in the topic's space:\n",
    "#Because this space is sparse, we will choose manhattan distances\n",
    "X_tags_topics_nmf = df_tags_topics_nmf.values\n",
    "X_word_topics_nmf = df_words_topics_nmf.values\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "df_nmf_tags_similarity = pd.DataFrame(manhattan_distances(X_tags_topics_nmf),columns=df_tags_topics_nmf.index, index=df_tags_topics_nmf.index)\n",
    "df_nmf_words_similarity = pd.DataFrame(manhattan_distances(X_word_topics_nmf),columns=df_words_topics_nmf.index, index=df_words_topics_nmf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the LDA word/tags similatities matrices\n"
     ]
    }
   ],
   "source": [
    "print(\"Building the LDA word/tags similatities matrices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With this two dataframes, we can compute the similarities between tags and words (with tags) in the topic's space:\n",
    "X_tags_topics = df_tags_topics_lda.values\n",
    "X_word_topics = df_tags_topics_lda.values\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df_lda_tags_similarity = pd.DataFrame(cosine_similarity(X_tags_topics),columns=df_tags_topics_lda.index, index=df_tags_topics_lda.index)\n",
    "df_lda_words_similarity = pd.DataFrame(cosine_similarity(X_word_topics),columns=df_tags_topics_lda.index, index=df_tags_topics_lda.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics management : building the topics/tags and topics/words dict for NMF and LDA\n"
     ]
    }
   ],
   "source": [
    "print(\"Topics management : building the topics/tags and topics/words dict for NMF and LDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_topics_tags_nmf = {}\n",
    "dict_topics_words_nmf = {}\n",
    "dict_topics_tags_lda = {}\n",
    "dict_topics_words_lda = {}\n",
    "\n",
    "for topic in L_topics:\n",
    "    L_heavy_tags = list(df_tags_topics_nmf[df_tags_topics_nmf[topic]>=TOPICS_THRESHOLD].index)\n",
    "    dict_topics_tags_nmf[topic] = L_heavy_tags\n",
    "    L_heavy_tags = list(df_tags_topics_lda[df_tags_topics_lda[topic]>=TOPICS_THRESHOLD].index)\n",
    "    dict_topics_tags_lda[topic] = L_heavy_tags\n",
    "    \n",
    "    L_heavy_words = list(df_words_topics_nmf[df_words_topics_nmf[topic]>=TOPICS_THRESHOLD].index)\n",
    "    dict_topics_words_nmf[topic] = L_heavy_words\n",
    "    L_heavy_words = list(df_words_topics_lda[df_words_topics_lda[topic]>=TOPICS_THRESHOLD].index)\n",
    "    dict_topics_words_lda[topic] = L_heavy_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Implementation\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec Implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_word2vec = df_train_lda.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.555360555648804 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "from gensim.models import word2vec\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# tokenize sentences in corpus\n",
    "corpus = df_train_word2vec['corpus'].copy()\n",
    "tokenized_corpus = corpus.apply(word_tokenize)\n",
    "\n",
    "\n",
    "# Set values for various parameters\n",
    "feature_size = 100    # Word vector dimensionality  \n",
    "window_context = 30          # Context window size                                                                                    \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "sample = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size,\n",
    "                              window=window_context, min_count=min_word_count,\n",
    "                              sample=sample, iter=100,\n",
    "                              workers=6)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_tags_word2vec = [tag for tag in L_frequent_tags if tag in vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_word2vec_words = [word for word in vectors.vocab.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the Word2Vec word/tags similatities matrices\n"
     ]
    }
   ],
   "source": [
    "print(\"Building the Word2Vec word/tags similatities matrices\")\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_word2vec_words_coordinates = pd.DataFrame(columns = [i for i in range(0,100)])\n",
    "for word in L_word2vec_words:\n",
    "    df_word_coordinates = pd.DataFrame(vectors[word]).T\n",
    "    df_word_coordinates.index = [word]\n",
    "    df_word2vec_words_coordinates = df_word2vec_words_coordinates.append(df_word_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word2vec_tags_coordinates = df_word2vec_words_coordinates.loc[L_tags_word2vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.142046689987183 seconds ---\n"
     ]
    }
   ],
   "source": [
    "X_tags_word2vec = df_word2vec_tags_coordinates.values\n",
    "X_words_word2vec = df_word2vec_words_coordinates.values\n",
    "\n",
    "df_word2vec_tags_similarity = pd.DataFrame(cosine_similarity(X_tags_word2vec),\\\n",
    "                                           columns=df_word2vec_tags_coordinates.index,\\\n",
    "                                           index=df_word2vec_tags_coordinates.index)\n",
    "\n",
    "df_word2vec_words_similarity = pd.DataFrame(cosine_similarity(X_words_word2vec),\\\n",
    "                                            columns=df_word2vec_words_coordinates.index,\\\n",
    "                                            index=df_word2vec_words_coordinates.index)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec moodel training on the pure corpus of tag lists\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec moodel training on the pure corpus of tag lists\")\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_corpus = df_train[['tag_list']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Managing the tag list for the train\n"
     ]
    }
   ],
   "source": [
    "print(\"Managing the tag list for the train\")\n",
    "dict_tags_replacement = pickle.load(open(pickles_path+\"dict_tags_replacement.p\", \"rb\" ))\n",
    "reverse_dict_tags_replacement = {v: k for k, v in dict_tags_replacement.items()}\n",
    "\n",
    "tags_corpus['raw_tag_list'] = tags_corpus['tag_list'].apply(lambda x : [reverse_dict_tags_replacement[tag] for tag in x])\n",
    "\n",
    "for col in ['raw_tag_list','tag_list']:\n",
    "    tags_corpus[col] = tags_corpus[col].astype(str)\n",
    "tags_corpus['tag_list'] = tags_corpus['tag_list']+tags_corpus['raw_tag_list']\n",
    "tags_corpus.drop('raw_tag_list', axis=1, inplace=True)\n",
    "\n",
    "dict_replacement = {'[-\\. ]':' ','[cC] {0,1}#':'csharp','[\\[\\]\\',]':' ',' +':' '}\n",
    "for pattern, replacement in dict_replacement.items():\n",
    "    tags_corpus['tag_list'] = tags_corpus['tag_list'].str.replace(pattern,replacement)\n",
    "\n",
    "tags_corpus['tag_list'] = tags_corpus['tag_list'].apply(word_tokenize)\n",
    "tokenized_tags_corpus = list(tags_corpus['tag_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the pure tags Word2Vec model\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting the pure tags Word2Vec model\")\n",
    "feature_size = 50    # Word vector dimensionality  \n",
    "window_context = 30          # Context window size                                                                                    \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "sample = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "w2v_pure_tags_model = word2vec.Word2Vec(tokenized_tags_corpus, size=feature_size,\n",
    "                              window=window_context, min_count=min_word_count,\n",
    "                              sample=sample, iter=100,\n",
    "                              workers=6)\n",
    "pure_tags_vectors = w2v_pure_tags_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the pure tags similarity matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csharp</th>\n",
       "      <th>winforms</th>\n",
       "      <th>net</th>\n",
       "      <th>datetime</th>\n",
       "      <th>math</th>\n",
       "      <th>linq</th>\n",
       "      <th>webservices</th>\n",
       "      <th>net35</th>\n",
       "      <th>web</th>\n",
       "      <th>services</th>\n",
       "      <th>...</th>\n",
       "      <th>projectmanagement</th>\n",
       "      <th>project</th>\n",
       "      <th>management</th>\n",
       "      <th>django</th>\n",
       "      <th>xcode</th>\n",
       "      <th>ssis</th>\n",
       "      <th>gcc</th>\n",
       "      <th>googlechrome</th>\n",
       "      <th>google</th>\n",
       "      <th>chrome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>csharp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.566398</td>\n",
       "      <td>0.770303</td>\n",
       "      <td>0.093344</td>\n",
       "      <td>-0.227306</td>\n",
       "      <td>0.500244</td>\n",
       "      <td>0.313661</td>\n",
       "      <td>0.472975</td>\n",
       "      <td>0.245507</td>\n",
       "      <td>0.292474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064704</td>\n",
       "      <td>0.057824</td>\n",
       "      <td>0.069184</td>\n",
       "      <td>-0.179043</td>\n",
       "      <td>-0.431871</td>\n",
       "      <td>-0.097085</td>\n",
       "      <td>0.067722</td>\n",
       "      <td>-0.157474</td>\n",
       "      <td>-0.162377</td>\n",
       "      <td>-0.174793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winforms</th>\n",
       "      <td>0.566398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.446778</td>\n",
       "      <td>-0.008520</td>\n",
       "      <td>-0.147843</td>\n",
       "      <td>0.092387</td>\n",
       "      <td>0.138505</td>\n",
       "      <td>0.387025</td>\n",
       "      <td>0.049098</td>\n",
       "      <td>0.189758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089723</td>\n",
       "      <td>0.087352</td>\n",
       "      <td>0.083498</td>\n",
       "      <td>-0.228200</td>\n",
       "      <td>-0.236443</td>\n",
       "      <td>-0.011572</td>\n",
       "      <td>0.172127</td>\n",
       "      <td>-0.142357</td>\n",
       "      <td>-0.146068</td>\n",
       "      <td>-0.151426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net</th>\n",
       "      <td>0.770303</td>\n",
       "      <td>0.446778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.051234</td>\n",
       "      <td>-0.302267</td>\n",
       "      <td>0.401373</td>\n",
       "      <td>0.408789</td>\n",
       "      <td>0.592367</td>\n",
       "      <td>0.280396</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020307</td>\n",
       "      <td>-0.023723</td>\n",
       "      <td>-0.014385</td>\n",
       "      <td>-0.196501</td>\n",
       "      <td>-0.431221</td>\n",
       "      <td>-0.121647</td>\n",
       "      <td>-0.070277</td>\n",
       "      <td>-0.149643</td>\n",
       "      <td>-0.140268</td>\n",
       "      <td>-0.163680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>0.093344</td>\n",
       "      <td>-0.008520</td>\n",
       "      <td>-0.051234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194286</td>\n",
       "      <td>0.228790</td>\n",
       "      <td>-0.085031</td>\n",
       "      <td>-0.151194</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>0.058921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222443</td>\n",
       "      <td>-0.230598</td>\n",
       "      <td>-0.222648</td>\n",
       "      <td>0.089277</td>\n",
       "      <td>-0.119481</td>\n",
       "      <td>0.280952</td>\n",
       "      <td>-0.133267</td>\n",
       "      <td>-0.235564</td>\n",
       "      <td>-0.236106</td>\n",
       "      <td>-0.248325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>-0.227306</td>\n",
       "      <td>-0.147843</td>\n",
       "      <td>-0.302267</td>\n",
       "      <td>0.194286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>-0.096500</td>\n",
       "      <td>-0.316790</td>\n",
       "      <td>-0.126464</td>\n",
       "      <td>-0.099828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151793</td>\n",
       "      <td>0.147870</td>\n",
       "      <td>0.139799</td>\n",
       "      <td>0.044212</td>\n",
       "      <td>0.172691</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>0.170354</td>\n",
       "      <td>0.174301</td>\n",
       "      <td>0.183933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linq</th>\n",
       "      <td>0.500244</td>\n",
       "      <td>0.092387</td>\n",
       "      <td>0.401373</td>\n",
       "      <td>0.228790</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222441</td>\n",
       "      <td>0.498243</td>\n",
       "      <td>0.186103</td>\n",
       "      <td>0.308208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>-0.134909</td>\n",
       "      <td>-0.158620</td>\n",
       "      <td>0.095513</td>\n",
       "      <td>-0.152909</td>\n",
       "      <td>-0.260557</td>\n",
       "      <td>-0.277694</td>\n",
       "      <td>-0.279071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webservices</th>\n",
       "      <td>0.313661</td>\n",
       "      <td>0.138505</td>\n",
       "      <td>0.408789</td>\n",
       "      <td>-0.085031</td>\n",
       "      <td>-0.096500</td>\n",
       "      <td>0.222441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.235499</td>\n",
       "      <td>0.527316</td>\n",
       "      <td>0.614818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010690</td>\n",
       "      <td>-0.025874</td>\n",
       "      <td>-0.005767</td>\n",
       "      <td>-0.107428</td>\n",
       "      <td>-0.388371</td>\n",
       "      <td>-0.153298</td>\n",
       "      <td>-0.042258</td>\n",
       "      <td>-0.068114</td>\n",
       "      <td>-0.059132</td>\n",
       "      <td>-0.080950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net35</th>\n",
       "      <td>0.472975</td>\n",
       "      <td>0.387025</td>\n",
       "      <td>0.592367</td>\n",
       "      <td>-0.151194</td>\n",
       "      <td>-0.316790</td>\n",
       "      <td>0.498243</td>\n",
       "      <td>0.235499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142621</td>\n",
       "      <td>0.207576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>-0.299642</td>\n",
       "      <td>-0.221236</td>\n",
       "      <td>-0.232364</td>\n",
       "      <td>-0.007241</td>\n",
       "      <td>-0.148847</td>\n",
       "      <td>-0.143669</td>\n",
       "      <td>-0.163694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>0.245507</td>\n",
       "      <td>0.049098</td>\n",
       "      <td>0.280396</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>-0.126464</td>\n",
       "      <td>0.186103</td>\n",
       "      <td>0.527316</td>\n",
       "      <td>0.142621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643264</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199889</td>\n",
       "      <td>-0.214108</td>\n",
       "      <td>-0.194130</td>\n",
       "      <td>-0.035843</td>\n",
       "      <td>-0.375200</td>\n",
       "      <td>-0.111232</td>\n",
       "      <td>0.027515</td>\n",
       "      <td>0.062164</td>\n",
       "      <td>0.059372</td>\n",
       "      <td>0.043919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>services</th>\n",
       "      <td>0.292474</td>\n",
       "      <td>0.189758</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>0.058921</td>\n",
       "      <td>-0.099828</td>\n",
       "      <td>0.308208</td>\n",
       "      <td>0.614818</td>\n",
       "      <td>0.207576</td>\n",
       "      <td>0.643264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015992</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.023857</td>\n",
       "      <td>-0.147855</td>\n",
       "      <td>-0.316838</td>\n",
       "      <td>0.055615</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>-0.047056</td>\n",
       "      <td>-0.057971</td>\n",
       "      <td>-0.065465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.560097</td>\n",
       "      <td>0.445657</td>\n",
       "      <td>0.604676</td>\n",
       "      <td>-0.149797</td>\n",
       "      <td>-0.239837</td>\n",
       "      <td>0.421625</td>\n",
       "      <td>0.335846</td>\n",
       "      <td>0.852441</td>\n",
       "      <td>0.139067</td>\n",
       "      <td>0.242827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057981</td>\n",
       "      <td>0.055265</td>\n",
       "      <td>0.060874</td>\n",
       "      <td>-0.322312</td>\n",
       "      <td>-0.415422</td>\n",
       "      <td>-0.225073</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-0.013205</td>\n",
       "      <td>-0.000993</td>\n",
       "      <td>-0.013048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.517387</td>\n",
       "      <td>0.375565</td>\n",
       "      <td>0.581272</td>\n",
       "      <td>-0.135178</td>\n",
       "      <td>-0.333670</td>\n",
       "      <td>0.546963</td>\n",
       "      <td>0.296228</td>\n",
       "      <td>0.972923</td>\n",
       "      <td>0.179181</td>\n",
       "      <td>0.205237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035886</td>\n",
       "      <td>0.022609</td>\n",
       "      <td>0.036821</td>\n",
       "      <td>-0.302099</td>\n",
       "      <td>-0.248059</td>\n",
       "      <td>-0.221808</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>-0.212923</td>\n",
       "      <td>-0.206192</td>\n",
       "      <td>-0.226366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>database</th>\n",
       "      <td>-0.126157</td>\n",
       "      <td>-0.089120</td>\n",
       "      <td>-0.155829</td>\n",
       "      <td>0.154586</td>\n",
       "      <td>-0.045647</td>\n",
       "      <td>0.245556</td>\n",
       "      <td>-0.109869</td>\n",
       "      <td>-0.096438</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.073720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087232</td>\n",
       "      <td>-0.043525</td>\n",
       "      <td>-0.084179</td>\n",
       "      <td>0.398257</td>\n",
       "      <td>0.219522</td>\n",
       "      <td>0.113575</td>\n",
       "      <td>-0.007699</td>\n",
       "      <td>-0.043280</td>\n",
       "      <td>-0.062990</td>\n",
       "      <td>-0.043515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mysql</th>\n",
       "      <td>-0.218587</td>\n",
       "      <td>-0.278669</td>\n",
       "      <td>-0.296061</td>\n",
       "      <td>0.442059</td>\n",
       "      <td>0.174024</td>\n",
       "      <td>0.113053</td>\n",
       "      <td>-0.198212</td>\n",
       "      <td>-0.314818</td>\n",
       "      <td>-0.002684</td>\n",
       "      <td>-0.061339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141750</td>\n",
       "      <td>-0.112594</td>\n",
       "      <td>-0.138778</td>\n",
       "      <td>0.429127</td>\n",
       "      <td>0.094437</td>\n",
       "      <td>0.261517</td>\n",
       "      <td>0.207747</td>\n",
       "      <td>-0.037779</td>\n",
       "      <td>-0.037238</td>\n",
       "      <td>-0.021818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>0.268374</td>\n",
       "      <td>0.202659</td>\n",
       "      <td>0.210253</td>\n",
       "      <td>0.272664</td>\n",
       "      <td>0.031446</td>\n",
       "      <td>0.300421</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.147599</td>\n",
       "      <td>0.143067</td>\n",
       "      <td>0.040876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351383</td>\n",
       "      <td>-0.358005</td>\n",
       "      <td>-0.364200</td>\n",
       "      <td>-0.052039</td>\n",
       "      <td>-0.147571</td>\n",
       "      <td>-0.058325</td>\n",
       "      <td>0.328773</td>\n",
       "      <td>-0.204776</td>\n",
       "      <td>-0.197326</td>\n",
       "      <td>-0.199742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unix</th>\n",
       "      <td>-0.133995</td>\n",
       "      <td>-0.173618</td>\n",
       "      <td>-0.152642</td>\n",
       "      <td>0.213787</td>\n",
       "      <td>0.541727</td>\n",
       "      <td>-0.098713</td>\n",
       "      <td>0.044687</td>\n",
       "      <td>-0.199405</td>\n",
       "      <td>0.049449</td>\n",
       "      <td>-0.017235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032546</td>\n",
       "      <td>-0.065737</td>\n",
       "      <td>-0.061929</td>\n",
       "      <td>-0.164504</td>\n",
       "      <td>-0.008220</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.344720</td>\n",
       "      <td>0.134415</td>\n",
       "      <td>0.170218</td>\n",
       "      <td>0.156534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>-0.066240</td>\n",
       "      <td>-0.092101</td>\n",
       "      <td>-0.217870</td>\n",
       "      <td>0.209151</td>\n",
       "      <td>0.549121</td>\n",
       "      <td>0.064745</td>\n",
       "      <td>-0.086614</td>\n",
       "      <td>-0.100914</td>\n",
       "      <td>-0.096739</td>\n",
       "      <td>-0.187645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103851</td>\n",
       "      <td>0.113464</td>\n",
       "      <td>0.084675</td>\n",
       "      <td>0.151176</td>\n",
       "      <td>-0.064551</td>\n",
       "      <td>-0.011091</td>\n",
       "      <td>0.200006</td>\n",
       "      <td>0.028652</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.062942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>languageagnostic</th>\n",
       "      <td>-0.107385</td>\n",
       "      <td>-0.229830</td>\n",
       "      <td>-0.127995</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.240714</td>\n",
       "      <td>-0.065645</td>\n",
       "      <td>0.061578</td>\n",
       "      <td>-0.114958</td>\n",
       "      <td>0.062185</td>\n",
       "      <td>-0.171770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076114</td>\n",
       "      <td>-0.061300</td>\n",
       "      <td>-0.086680</td>\n",
       "      <td>0.201462</td>\n",
       "      <td>0.044288</td>\n",
       "      <td>-0.136653</td>\n",
       "      <td>0.121310</td>\n",
       "      <td>0.027422</td>\n",
       "      <td>0.050939</td>\n",
       "      <td>0.051593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>-0.122413</td>\n",
       "      <td>-0.226291</td>\n",
       "      <td>-0.260322</td>\n",
       "      <td>0.051635</td>\n",
       "      <td>0.295601</td>\n",
       "      <td>-0.073815</td>\n",
       "      <td>-0.084156</td>\n",
       "      <td>-0.020723</td>\n",
       "      <td>0.064047</td>\n",
       "      <td>-0.195430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009668</td>\n",
       "      <td>-0.001610</td>\n",
       "      <td>-0.013701</td>\n",
       "      <td>0.131696</td>\n",
       "      <td>0.116051</td>\n",
       "      <td>-0.053588</td>\n",
       "      <td>0.176025</td>\n",
       "      <td>0.140256</td>\n",
       "      <td>0.149504</td>\n",
       "      <td>0.152430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agnostic</th>\n",
       "      <td>-0.199725</td>\n",
       "      <td>-0.321069</td>\n",
       "      <td>-0.236514</td>\n",
       "      <td>0.051480</td>\n",
       "      <td>0.272483</td>\n",
       "      <td>-0.145130</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.140409</td>\n",
       "      <td>-0.029183</td>\n",
       "      <td>-0.237268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082549</td>\n",
       "      <td>-0.070377</td>\n",
       "      <td>-0.090565</td>\n",
       "      <td>0.216714</td>\n",
       "      <td>0.094534</td>\n",
       "      <td>-0.076919</td>\n",
       "      <td>0.112624</td>\n",
       "      <td>0.069040</td>\n",
       "      <td>0.086433</td>\n",
       "      <td>0.089676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triggers</th>\n",
       "      <td>-0.156103</td>\n",
       "      <td>-0.189605</td>\n",
       "      <td>-0.284467</td>\n",
       "      <td>0.307763</td>\n",
       "      <td>0.049651</td>\n",
       "      <td>0.113006</td>\n",
       "      <td>-0.242308</td>\n",
       "      <td>-0.342695</td>\n",
       "      <td>-0.023795</td>\n",
       "      <td>-0.051219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077929</td>\n",
       "      <td>0.106627</td>\n",
       "      <td>0.073104</td>\n",
       "      <td>0.287620</td>\n",
       "      <td>0.186824</td>\n",
       "      <td>0.415866</td>\n",
       "      <td>0.041727</td>\n",
       "      <td>0.215826</td>\n",
       "      <td>0.221336</td>\n",
       "      <td>0.240440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sockets</th>\n",
       "      <td>-0.082433</td>\n",
       "      <td>-0.151339</td>\n",
       "      <td>-0.182894</td>\n",
       "      <td>0.203372</td>\n",
       "      <td>0.231784</td>\n",
       "      <td>0.025063</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>-0.171751</td>\n",
       "      <td>-0.015419</td>\n",
       "      <td>-0.128116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094771</td>\n",
       "      <td>-0.109072</td>\n",
       "      <td>-0.106859</td>\n",
       "      <td>-0.023662</td>\n",
       "      <td>-0.062941</td>\n",
       "      <td>-0.061278</td>\n",
       "      <td>0.150240</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>-0.072482</td>\n",
       "      <td>-0.068579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c++</th>\n",
       "      <td>0.092675</td>\n",
       "      <td>0.223539</td>\n",
       "      <td>-0.137463</td>\n",
       "      <td>-0.012913</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>-0.221578</td>\n",
       "      <td>-0.028536</td>\n",
       "      <td>-0.143943</td>\n",
       "      <td>-0.093068</td>\n",
       "      <td>-0.108870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086566</td>\n",
       "      <td>0.068943</td>\n",
       "      <td>0.066483</td>\n",
       "      <td>-0.016346</td>\n",
       "      <td>0.021770</td>\n",
       "      <td>-0.054775</td>\n",
       "      <td>0.730737</td>\n",
       "      <td>0.110222</td>\n",
       "      <td>0.124397</td>\n",
       "      <td>0.136864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>-0.173465</td>\n",
       "      <td>-0.083831</td>\n",
       "      <td>-0.310477</td>\n",
       "      <td>-0.062022</td>\n",
       "      <td>0.251985</td>\n",
       "      <td>-0.252496</td>\n",
       "      <td>-0.180828</td>\n",
       "      <td>-0.236815</td>\n",
       "      <td>-0.172127</td>\n",
       "      <td>-0.229798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118058</td>\n",
       "      <td>0.100393</td>\n",
       "      <td>0.100807</td>\n",
       "      <td>-0.017167</td>\n",
       "      <td>0.375247</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.629540</td>\n",
       "      <td>0.099498</td>\n",
       "      <td>0.110758</td>\n",
       "      <td>0.134397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flex</th>\n",
       "      <td>0.020038</td>\n",
       "      <td>-0.035438</td>\n",
       "      <td>0.044738</td>\n",
       "      <td>0.244526</td>\n",
       "      <td>-0.065025</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.285539</td>\n",
       "      <td>0.239302</td>\n",
       "      <td>0.151466</td>\n",
       "      <td>0.175666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021724</td>\n",
       "      <td>-0.034478</td>\n",
       "      <td>-0.017484</td>\n",
       "      <td>-0.132346</td>\n",
       "      <td>0.025377</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.077450</td>\n",
       "      <td>0.092466</td>\n",
       "      <td>0.075946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actionscript3</th>\n",
       "      <td>0.076253</td>\n",
       "      <td>-0.053107</td>\n",
       "      <td>0.081453</td>\n",
       "      <td>0.093264</td>\n",
       "      <td>-0.063675</td>\n",
       "      <td>0.166203</td>\n",
       "      <td>0.172374</td>\n",
       "      <td>0.393485</td>\n",
       "      <td>-0.069899</td>\n",
       "      <td>0.056514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154007</td>\n",
       "      <td>0.150334</td>\n",
       "      <td>0.163391</td>\n",
       "      <td>-0.157322</td>\n",
       "      <td>0.046678</td>\n",
       "      <td>-0.020416</td>\n",
       "      <td>0.090894</td>\n",
       "      <td>0.073811</td>\n",
       "      <td>0.090310</td>\n",
       "      <td>0.085023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrays</th>\n",
       "      <td>-0.078476</td>\n",
       "      <td>-0.096441</td>\n",
       "      <td>-0.037244</td>\n",
       "      <td>0.256096</td>\n",
       "      <td>0.120356</td>\n",
       "      <td>-0.044259</td>\n",
       "      <td>-0.012647</td>\n",
       "      <td>0.061095</td>\n",
       "      <td>0.036728</td>\n",
       "      <td>-0.028075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077623</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>0.082148</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>-0.150350</td>\n",
       "      <td>-0.129818</td>\n",
       "      <td>0.147037</td>\n",
       "      <td>-0.079557</td>\n",
       "      <td>-0.074525</td>\n",
       "      <td>-0.065675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actionscript</th>\n",
       "      <td>0.088230</td>\n",
       "      <td>-0.054890</td>\n",
       "      <td>0.123062</td>\n",
       "      <td>0.093123</td>\n",
       "      <td>-0.071748</td>\n",
       "      <td>0.178690</td>\n",
       "      <td>0.156750</td>\n",
       "      <td>0.432757</td>\n",
       "      <td>-0.070065</td>\n",
       "      <td>0.045435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149259</td>\n",
       "      <td>0.142773</td>\n",
       "      <td>0.159560</td>\n",
       "      <td>-0.175708</td>\n",
       "      <td>0.078958</td>\n",
       "      <td>-0.031844</td>\n",
       "      <td>0.085649</td>\n",
       "      <td>0.040626</td>\n",
       "      <td>0.056363</td>\n",
       "      <td>0.049357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqlserver</th>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.036773</td>\n",
       "      <td>0.037286</td>\n",
       "      <td>0.289610</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.333064</td>\n",
       "      <td>0.024368</td>\n",
       "      <td>-0.047220</td>\n",
       "      <td>0.042341</td>\n",
       "      <td>0.132320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056055</td>\n",
       "      <td>0.060797</td>\n",
       "      <td>0.053712</td>\n",
       "      <td>0.160027</td>\n",
       "      <td>-0.023467</td>\n",
       "      <td>0.526679</td>\n",
       "      <td>-0.085275</td>\n",
       "      <td>-0.090599</td>\n",
       "      <td>-0.096311</td>\n",
       "      <td>-0.092245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sql</th>\n",
       "      <td>0.113806</td>\n",
       "      <td>0.050695</td>\n",
       "      <td>-0.017731</td>\n",
       "      <td>0.298267</td>\n",
       "      <td>-0.077350</td>\n",
       "      <td>0.428112</td>\n",
       "      <td>-0.020789</td>\n",
       "      <td>-0.054950</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.161121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021585</td>\n",
       "      <td>-0.011987</td>\n",
       "      <td>-0.027456</td>\n",
       "      <td>0.048622</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>0.663381</td>\n",
       "      <td>0.024642</td>\n",
       "      <td>-0.177375</td>\n",
       "      <td>-0.184730</td>\n",
       "      <td>-0.176295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coding</th>\n",
       "      <td>-0.111465</td>\n",
       "      <td>0.024461</td>\n",
       "      <td>-0.119088</td>\n",
       "      <td>0.134289</td>\n",
       "      <td>0.127989</td>\n",
       "      <td>-0.083455</td>\n",
       "      <td>-0.118463</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>-0.048561</td>\n",
       "      <td>-0.108131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079709</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>0.068159</td>\n",
       "      <td>0.084486</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>-0.152478</td>\n",
       "      <td>0.016733</td>\n",
       "      <td>-0.076554</td>\n",
       "      <td>-0.064880</td>\n",
       "      <td>-0.055179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>style</th>\n",
       "      <td>-0.078451</td>\n",
       "      <td>0.026357</td>\n",
       "      <td>-0.089141</td>\n",
       "      <td>0.143233</td>\n",
       "      <td>0.104617</td>\n",
       "      <td>-0.054437</td>\n",
       "      <td>-0.087930</td>\n",
       "      <td>0.062477</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>-0.085483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.060870</td>\n",
       "      <td>0.045690</td>\n",
       "      <td>0.100293</td>\n",
       "      <td>-0.001036</td>\n",
       "      <td>-0.165329</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>-0.107061</td>\n",
       "      <td>-0.096082</td>\n",
       "      <td>-0.087191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>api</th>\n",
       "      <td>0.157823</td>\n",
       "      <td>0.074569</td>\n",
       "      <td>-0.066417</td>\n",
       "      <td>-0.043693</td>\n",
       "      <td>-0.009045</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.269012</td>\n",
       "      <td>-0.072742</td>\n",
       "      <td>0.320752</td>\n",
       "      <td>0.286330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>-0.008269</td>\n",
       "      <td>0.086117</td>\n",
       "      <td>-0.243281</td>\n",
       "      <td>-0.099902</td>\n",
       "      <td>0.396984</td>\n",
       "      <td>0.278039</td>\n",
       "      <td>0.255137</td>\n",
       "      <td>0.258314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moss</th>\n",
       "      <td>-0.138518</td>\n",
       "      <td>-0.089694</td>\n",
       "      <td>-0.123893</td>\n",
       "      <td>-0.020707</td>\n",
       "      <td>0.350619</td>\n",
       "      <td>-0.018801</td>\n",
       "      <td>0.237179</td>\n",
       "      <td>-0.192632</td>\n",
       "      <td>-0.022667</td>\n",
       "      <td>0.106722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235750</td>\n",
       "      <td>0.236153</td>\n",
       "      <td>0.231446</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.281899</td>\n",
       "      <td>0.311607</td>\n",
       "      <td>0.066676</td>\n",
       "      <td>0.252141</td>\n",
       "      <td>0.258608</td>\n",
       "      <td>0.247590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net20</th>\n",
       "      <td>0.385448</td>\n",
       "      <td>0.247242</td>\n",
       "      <td>0.562733</td>\n",
       "      <td>-0.144659</td>\n",
       "      <td>-0.117190</td>\n",
       "      <td>0.183622</td>\n",
       "      <td>0.126023</td>\n",
       "      <td>0.459659</td>\n",
       "      <td>0.090172</td>\n",
       "      <td>0.111089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200273</td>\n",
       "      <td>0.185696</td>\n",
       "      <td>0.212731</td>\n",
       "      <td>-0.196490</td>\n",
       "      <td>-0.015053</td>\n",
       "      <td>-0.120237</td>\n",
       "      <td>-0.102719</td>\n",
       "      <td>-0.135580</td>\n",
       "      <td>-0.132775</td>\n",
       "      <td>-0.144445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.361581</td>\n",
       "      <td>0.221866</td>\n",
       "      <td>0.553668</td>\n",
       "      <td>-0.139891</td>\n",
       "      <td>-0.144099</td>\n",
       "      <td>0.185255</td>\n",
       "      <td>0.139752</td>\n",
       "      <td>0.454970</td>\n",
       "      <td>0.106617</td>\n",
       "      <td>0.139992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170690</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>0.184812</td>\n",
       "      <td>-0.191904</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>-0.109617</td>\n",
       "      <td>-0.092510</td>\n",
       "      <td>-0.138529</td>\n",
       "      <td>-0.137728</td>\n",
       "      <td>-0.150778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.380609</td>\n",
       "      <td>0.241275</td>\n",
       "      <td>0.562869</td>\n",
       "      <td>-0.142678</td>\n",
       "      <td>-0.130069</td>\n",
       "      <td>0.186417</td>\n",
       "      <td>0.121356</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>0.083446</td>\n",
       "      <td>0.110834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177952</td>\n",
       "      <td>0.163073</td>\n",
       "      <td>0.190531</td>\n",
       "      <td>-0.207649</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.142727</td>\n",
       "      <td>-0.063141</td>\n",
       "      <td>-0.133769</td>\n",
       "      <td>-0.132652</td>\n",
       "      <td>-0.143530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windowsinstaller</th>\n",
       "      <td>0.162511</td>\n",
       "      <td>0.289411</td>\n",
       "      <td>0.208367</td>\n",
       "      <td>-0.008046</td>\n",
       "      <td>0.036340</td>\n",
       "      <td>0.079104</td>\n",
       "      <td>0.095150</td>\n",
       "      <td>0.258570</td>\n",
       "      <td>0.037811</td>\n",
       "      <td>0.207771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162502</td>\n",
       "      <td>0.145773</td>\n",
       "      <td>0.166024</td>\n",
       "      <td>-0.020578</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>0.254620</td>\n",
       "      <td>0.111356</td>\n",
       "      <td>-0.006278</td>\n",
       "      <td>-0.022072</td>\n",
       "      <td>-0.030307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>-0.038102</td>\n",
       "      <td>-0.122136</td>\n",
       "      <td>0.205659</td>\n",
       "      <td>-0.013129</td>\n",
       "      <td>0.218223</td>\n",
       "      <td>0.056016</td>\n",
       "      <td>0.326873</td>\n",
       "      <td>0.090944</td>\n",
       "      <td>0.293087</td>\n",
       "      <td>0.315278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.026071</td>\n",
       "      <td>-0.189280</td>\n",
       "      <td>-0.193708</td>\n",
       "      <td>-0.015870</td>\n",
       "      <td>-0.092641</td>\n",
       "      <td>0.088857</td>\n",
       "      <td>0.102987</td>\n",
       "      <td>0.094430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inheritance</th>\n",
       "      <td>0.368412</td>\n",
       "      <td>0.371815</td>\n",
       "      <td>0.196680</td>\n",
       "      <td>-0.084791</td>\n",
       "      <td>0.071498</td>\n",
       "      <td>0.261108</td>\n",
       "      <td>0.079810</td>\n",
       "      <td>0.135582</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.151842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235528</td>\n",
       "      <td>0.236972</td>\n",
       "      <td>0.232096</td>\n",
       "      <td>0.149753</td>\n",
       "      <td>0.016881</td>\n",
       "      <td>-0.072459</td>\n",
       "      <td>-0.085527</td>\n",
       "      <td>-0.091094</td>\n",
       "      <td>-0.123479</td>\n",
       "      <td>-0.110172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serialization</th>\n",
       "      <td>0.209109</td>\n",
       "      <td>0.057978</td>\n",
       "      <td>0.339698</td>\n",
       "      <td>0.020089</td>\n",
       "      <td>0.163968</td>\n",
       "      <td>0.315248</td>\n",
       "      <td>0.298384</td>\n",
       "      <td>0.279857</td>\n",
       "      <td>0.268799</td>\n",
       "      <td>0.337641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152579</td>\n",
       "      <td>0.144334</td>\n",
       "      <td>0.158567</td>\n",
       "      <td>-0.123071</td>\n",
       "      <td>-0.273647</td>\n",
       "      <td>-0.039342</td>\n",
       "      <td>-0.265844</td>\n",
       "      <td>-0.061390</td>\n",
       "      <td>-0.065664</td>\n",
       "      <td>-0.072423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsp</th>\n",
       "      <td>-0.236312</td>\n",
       "      <td>-0.129561</td>\n",
       "      <td>-0.234681</td>\n",
       "      <td>-0.056509</td>\n",
       "      <td>0.126209</td>\n",
       "      <td>-0.165101</td>\n",
       "      <td>-0.056436</td>\n",
       "      <td>-0.133205</td>\n",
       "      <td>0.058064</td>\n",
       "      <td>-0.155754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120055</td>\n",
       "      <td>0.126537</td>\n",
       "      <td>0.111213</td>\n",
       "      <td>-0.073672</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>-0.084378</td>\n",
       "      <td>-0.046971</td>\n",
       "      <td>0.070350</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.082928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resources</th>\n",
       "      <td>0.004594</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>-0.297185</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>-0.179250</td>\n",
       "      <td>0.174354</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.270211</td>\n",
       "      <td>0.094857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090069</td>\n",
       "      <td>0.100499</td>\n",
       "      <td>0.076287</td>\n",
       "      <td>0.140621</td>\n",
       "      <td>-0.063307</td>\n",
       "      <td>-0.356239</td>\n",
       "      <td>0.229920</td>\n",
       "      <td>0.482836</td>\n",
       "      <td>0.510663</td>\n",
       "      <td>0.518664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soap</th>\n",
       "      <td>0.007675</td>\n",
       "      <td>-0.006300</td>\n",
       "      <td>0.068686</td>\n",
       "      <td>0.105353</td>\n",
       "      <td>-0.031791</td>\n",
       "      <td>-0.038955</td>\n",
       "      <td>0.592132</td>\n",
       "      <td>0.076167</td>\n",
       "      <td>0.608768</td>\n",
       "      <td>0.564711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115448</td>\n",
       "      <td>0.090085</td>\n",
       "      <td>0.113052</td>\n",
       "      <td>-0.005761</td>\n",
       "      <td>-0.211802</td>\n",
       "      <td>-0.166253</td>\n",
       "      <td>0.132897</td>\n",
       "      <td>0.119036</td>\n",
       "      <td>0.112160</td>\n",
       "      <td>0.108715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nant</th>\n",
       "      <td>0.135456</td>\n",
       "      <td>0.104408</td>\n",
       "      <td>0.222647</td>\n",
       "      <td>-0.165829</td>\n",
       "      <td>0.240792</td>\n",
       "      <td>-0.016109</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.092709</td>\n",
       "      <td>-0.137668</td>\n",
       "      <td>0.096626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364177</td>\n",
       "      <td>0.367304</td>\n",
       "      <td>0.360375</td>\n",
       "      <td>0.045630</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>-0.225887</td>\n",
       "      <td>0.049047</td>\n",
       "      <td>0.278747</td>\n",
       "      <td>0.285547</td>\n",
       "      <td>0.277354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batchfile</th>\n",
       "      <td>-0.141777</td>\n",
       "      <td>-0.151423</td>\n",
       "      <td>-0.054517</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.201677</td>\n",
       "      <td>-0.182279</td>\n",
       "      <td>-0.101915</td>\n",
       "      <td>-0.320197</td>\n",
       "      <td>-0.083162</td>\n",
       "      <td>0.056249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293778</td>\n",
       "      <td>0.274961</td>\n",
       "      <td>0.287831</td>\n",
       "      <td>-0.021488</td>\n",
       "      <td>0.204622</td>\n",
       "      <td>0.507181</td>\n",
       "      <td>-0.023083</td>\n",
       "      <td>0.118395</td>\n",
       "      <td>0.106525</td>\n",
       "      <td>0.107558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch</th>\n",
       "      <td>-0.134676</td>\n",
       "      <td>-0.151257</td>\n",
       "      <td>-0.063340</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.209485</td>\n",
       "      <td>-0.174544</td>\n",
       "      <td>-0.089051</td>\n",
       "      <td>-0.322183</td>\n",
       "      <td>-0.061567</td>\n",
       "      <td>0.066377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305354</td>\n",
       "      <td>0.285785</td>\n",
       "      <td>0.299454</td>\n",
       "      <td>-0.008061</td>\n",
       "      <td>0.202259</td>\n",
       "      <td>0.505762</td>\n",
       "      <td>-0.005841</td>\n",
       "      <td>0.128364</td>\n",
       "      <td>0.116189</td>\n",
       "      <td>0.117439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>-0.079021</td>\n",
       "      <td>-0.182590</td>\n",
       "      <td>-0.011616</td>\n",
       "      <td>-0.117084</td>\n",
       "      <td>-0.089697</td>\n",
       "      <td>0.117846</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.209454</td>\n",
       "      <td>-0.253122</td>\n",
       "      <td>-0.075897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269712</td>\n",
       "      <td>0.300414</td>\n",
       "      <td>0.271070</td>\n",
       "      <td>0.154371</td>\n",
       "      <td>0.129830</td>\n",
       "      <td>-0.028662</td>\n",
       "      <td>-0.131404</td>\n",
       "      <td>0.124113</td>\n",
       "      <td>0.137976</td>\n",
       "      <td>0.153077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windowsserver2003</th>\n",
       "      <td>-0.106000</td>\n",
       "      <td>-0.163610</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.196599</td>\n",
       "      <td>-0.124634</td>\n",
       "      <td>0.102909</td>\n",
       "      <td>0.081118</td>\n",
       "      <td>-0.125862</td>\n",
       "      <td>0.161934</td>\n",
       "      <td>0.174298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031206</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.035362</td>\n",
       "      <td>0.086966</td>\n",
       "      <td>0.102762</td>\n",
       "      <td>0.552346</td>\n",
       "      <td>-0.308065</td>\n",
       "      <td>-0.035594</td>\n",
       "      <td>-0.057088</td>\n",
       "      <td>-0.071822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>-0.088174</td>\n",
       "      <td>-0.162152</td>\n",
       "      <td>0.027191</td>\n",
       "      <td>0.215464</td>\n",
       "      <td>-0.146168</td>\n",
       "      <td>0.129161</td>\n",
       "      <td>0.085192</td>\n",
       "      <td>-0.099412</td>\n",
       "      <td>0.158545</td>\n",
       "      <td>0.177771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.020160</td>\n",
       "      <td>0.093479</td>\n",
       "      <td>0.075214</td>\n",
       "      <td>0.562166</td>\n",
       "      <td>-0.318498</td>\n",
       "      <td>-0.076830</td>\n",
       "      <td>-0.096891</td>\n",
       "      <td>-0.112374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projectmanagement</th>\n",
       "      <td>0.064704</td>\n",
       "      <td>0.089723</td>\n",
       "      <td>-0.020307</td>\n",
       "      <td>-0.222443</td>\n",
       "      <td>0.151793</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>-0.010690</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>-0.199889</td>\n",
       "      <td>0.015992</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996407</td>\n",
       "      <td>0.998218</td>\n",
       "      <td>0.166261</td>\n",
       "      <td>0.138688</td>\n",
       "      <td>0.147594</td>\n",
       "      <td>-0.009999</td>\n",
       "      <td>0.146735</td>\n",
       "      <td>0.154205</td>\n",
       "      <td>0.169721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project</th>\n",
       "      <td>0.057824</td>\n",
       "      <td>0.087352</td>\n",
       "      <td>-0.023723</td>\n",
       "      <td>-0.230598</td>\n",
       "      <td>0.147870</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.025874</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.214108</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996428</td>\n",
       "      <td>0.199910</td>\n",
       "      <td>0.135342</td>\n",
       "      <td>0.137102</td>\n",
       "      <td>-0.013917</td>\n",
       "      <td>0.154459</td>\n",
       "      <td>0.160906</td>\n",
       "      <td>0.177629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>0.069184</td>\n",
       "      <td>0.083498</td>\n",
       "      <td>-0.014385</td>\n",
       "      <td>-0.222648</td>\n",
       "      <td>0.139799</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>-0.005767</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>-0.194130</td>\n",
       "      <td>0.023857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998218</td>\n",
       "      <td>0.996428</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173060</td>\n",
       "      <td>0.132103</td>\n",
       "      <td>0.145151</td>\n",
       "      <td>-0.023064</td>\n",
       "      <td>0.136170</td>\n",
       "      <td>0.141577</td>\n",
       "      <td>0.157411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>django</th>\n",
       "      <td>-0.179043</td>\n",
       "      <td>-0.228200</td>\n",
       "      <td>-0.196501</td>\n",
       "      <td>0.089277</td>\n",
       "      <td>0.044212</td>\n",
       "      <td>-0.134909</td>\n",
       "      <td>-0.107428</td>\n",
       "      <td>-0.299642</td>\n",
       "      <td>-0.035843</td>\n",
       "      <td>-0.147855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166261</td>\n",
       "      <td>0.199910</td>\n",
       "      <td>0.173060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134412</td>\n",
       "      <td>0.044895</td>\n",
       "      <td>-0.053504</td>\n",
       "      <td>0.137268</td>\n",
       "      <td>0.121730</td>\n",
       "      <td>0.135096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xcode</th>\n",
       "      <td>-0.431871</td>\n",
       "      <td>-0.236443</td>\n",
       "      <td>-0.431221</td>\n",
       "      <td>-0.119481</td>\n",
       "      <td>0.172691</td>\n",
       "      <td>-0.158620</td>\n",
       "      <td>-0.388371</td>\n",
       "      <td>-0.221236</td>\n",
       "      <td>-0.375200</td>\n",
       "      <td>-0.316838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138688</td>\n",
       "      <td>0.135342</td>\n",
       "      <td>0.132103</td>\n",
       "      <td>0.134412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194005</td>\n",
       "      <td>0.094029</td>\n",
       "      <td>0.102121</td>\n",
       "      <td>0.087101</td>\n",
       "      <td>0.105748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssis</th>\n",
       "      <td>-0.097085</td>\n",
       "      <td>-0.011572</td>\n",
       "      <td>-0.121647</td>\n",
       "      <td>0.280952</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.095513</td>\n",
       "      <td>-0.153298</td>\n",
       "      <td>-0.232364</td>\n",
       "      <td>-0.111232</td>\n",
       "      <td>0.055615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147594</td>\n",
       "      <td>0.137102</td>\n",
       "      <td>0.145151</td>\n",
       "      <td>0.044895</td>\n",
       "      <td>0.194005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.063756</td>\n",
       "      <td>-0.105655</td>\n",
       "      <td>-0.115650</td>\n",
       "      <td>-0.113854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcc</th>\n",
       "      <td>0.067722</td>\n",
       "      <td>0.172127</td>\n",
       "      <td>-0.070277</td>\n",
       "      <td>-0.133267</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>-0.152909</td>\n",
       "      <td>-0.042258</td>\n",
       "      <td>-0.007241</td>\n",
       "      <td>0.027515</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009999</td>\n",
       "      <td>-0.013917</td>\n",
       "      <td>-0.023064</td>\n",
       "      <td>-0.053504</td>\n",
       "      <td>0.094029</td>\n",
       "      <td>-0.063756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176159</td>\n",
       "      <td>0.184379</td>\n",
       "      <td>0.195592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>googlechrome</th>\n",
       "      <td>-0.157474</td>\n",
       "      <td>-0.142357</td>\n",
       "      <td>-0.149643</td>\n",
       "      <td>-0.235564</td>\n",
       "      <td>0.170354</td>\n",
       "      <td>-0.260557</td>\n",
       "      <td>-0.068114</td>\n",
       "      <td>-0.148847</td>\n",
       "      <td>0.062164</td>\n",
       "      <td>-0.047056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146735</td>\n",
       "      <td>0.154459</td>\n",
       "      <td>0.136170</td>\n",
       "      <td>0.137268</td>\n",
       "      <td>0.102121</td>\n",
       "      <td>-0.105655</td>\n",
       "      <td>0.176159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994905</td>\n",
       "      <td>0.994979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>-0.162377</td>\n",
       "      <td>-0.146068</td>\n",
       "      <td>-0.140268</td>\n",
       "      <td>-0.236106</td>\n",
       "      <td>0.174301</td>\n",
       "      <td>-0.277694</td>\n",
       "      <td>-0.059132</td>\n",
       "      <td>-0.143669</td>\n",
       "      <td>0.059372</td>\n",
       "      <td>-0.057971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154205</td>\n",
       "      <td>0.160906</td>\n",
       "      <td>0.141577</td>\n",
       "      <td>0.121730</td>\n",
       "      <td>0.087101</td>\n",
       "      <td>-0.115650</td>\n",
       "      <td>0.184379</td>\n",
       "      <td>0.994905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrome</th>\n",
       "      <td>-0.174793</td>\n",
       "      <td>-0.151426</td>\n",
       "      <td>-0.163680</td>\n",
       "      <td>-0.248325</td>\n",
       "      <td>0.183933</td>\n",
       "      <td>-0.279071</td>\n",
       "      <td>-0.080950</td>\n",
       "      <td>-0.163694</td>\n",
       "      <td>0.043919</td>\n",
       "      <td>-0.065465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169721</td>\n",
       "      <td>0.177629</td>\n",
       "      <td>0.157411</td>\n",
       "      <td>0.135096</td>\n",
       "      <td>0.105748</td>\n",
       "      <td>-0.113854</td>\n",
       "      <td>0.195592</td>\n",
       "      <td>0.994979</td>\n",
       "      <td>0.997540</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows  351 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     csharp  winforms       net  datetime      math      linq  \\\n",
       "csharp             1.000000  0.566398  0.770303  0.093344 -0.227306  0.500244   \n",
       "winforms           0.566398  1.000000  0.446778 -0.008520 -0.147843  0.092387   \n",
       "net                0.770303  0.446778  1.000000 -0.051234 -0.302267  0.401373   \n",
       "datetime           0.093344 -0.008520 -0.051234  1.000000  0.194286  0.228790   \n",
       "math              -0.227306 -0.147843 -0.302267  0.194286  1.000000  0.000425   \n",
       "linq               0.500244  0.092387  0.401373  0.228790  0.000425  1.000000   \n",
       "webservices        0.313661  0.138505  0.408789 -0.085031 -0.096500  0.222441   \n",
       "net35              0.472975  0.387025  0.592367 -0.151194 -0.316790  0.498243   \n",
       "web                0.245507  0.049098  0.280396  0.169922 -0.126464  0.186103   \n",
       "services           0.292474  0.189758  0.423699  0.058921 -0.099828  0.308208   \n",
       "3                  0.560097  0.445657  0.604676 -0.149797 -0.239837  0.421625   \n",
       "5                  0.517387  0.375565  0.581272 -0.135178 -0.333670  0.546963   \n",
       "database          -0.126157 -0.089120 -0.155829  0.154586 -0.045647  0.245556   \n",
       "mysql             -0.218587 -0.278669 -0.296061  0.442059  0.174024  0.113053   \n",
       "performance        0.268374  0.202659  0.210253  0.272664  0.031446  0.300421   \n",
       "unix              -0.133995 -0.173618 -0.152642  0.213787  0.541727 -0.098713   \n",
       "algorithm         -0.066240 -0.092101 -0.217870  0.209151  0.549121  0.064745   \n",
       "languageagnostic  -0.107385 -0.229830 -0.127995  0.048446  0.240714 -0.065645   \n",
       "language          -0.122413 -0.226291 -0.260322  0.051635  0.295601 -0.073815   \n",
       "agnostic          -0.199725 -0.321069 -0.236514  0.051480  0.272483 -0.145130   \n",
       "triggers          -0.156103 -0.189605 -0.284467  0.307763  0.049651  0.113006   \n",
       "sockets           -0.082433 -0.151339 -0.182894  0.203372  0.231784  0.025063   \n",
       "c++                0.092675  0.223539 -0.137463 -0.012913  0.090164 -0.221578   \n",
       "c                 -0.173465 -0.083831 -0.310477 -0.062022  0.251985 -0.252496   \n",
       "flex               0.020038 -0.035438  0.044738  0.244526 -0.065025  0.057756   \n",
       "actionscript3      0.076253 -0.053107  0.081453  0.093264 -0.063675  0.166203   \n",
       "arrays            -0.078476 -0.096441 -0.037244  0.256096  0.120356 -0.044259   \n",
       "actionscript       0.088230 -0.054890  0.123062  0.093123 -0.071748  0.178690   \n",
       "sqlserver          0.020348  0.036773  0.037286  0.289610  0.007317  0.333064   \n",
       "sql                0.113806  0.050695 -0.017731  0.298267 -0.077350  0.428112   \n",
       "...                     ...       ...       ...       ...       ...       ...   \n",
       "coding            -0.111465  0.024461 -0.119088  0.134289  0.127989 -0.083455   \n",
       "style             -0.078451  0.026357 -0.089141  0.143233  0.104617 -0.054437   \n",
       "api                0.157823  0.074569 -0.066417 -0.043693 -0.009045  0.021808   \n",
       "moss              -0.138518 -0.089694 -0.123893 -0.020707  0.350619 -0.018801   \n",
       "net20              0.385448  0.247242  0.562733 -0.144659 -0.117190  0.183622   \n",
       "2                  0.361581  0.221866  0.553668 -0.139891 -0.144099  0.185255   \n",
       "0                  0.380609  0.241275  0.562869 -0.142678 -0.130069  0.186417   \n",
       "windowsinstaller   0.162511  0.289411  0.208367 -0.008046  0.036340  0.079104   \n",
       "json              -0.038102 -0.122136  0.205659 -0.013129  0.218223  0.056016   \n",
       "inheritance        0.368412  0.371815  0.196680 -0.084791  0.071498  0.261108   \n",
       "serialization      0.209109  0.057978  0.339698  0.020089  0.163968  0.315248   \n",
       "jsp               -0.236312 -0.129561 -0.234681 -0.056509  0.126209 -0.165101   \n",
       "resources          0.004594 -0.010247  0.005737 -0.297185  0.187943 -0.179250   \n",
       "soap               0.007675 -0.006300  0.068686  0.105353 -0.031791 -0.038955   \n",
       "nant               0.135456  0.104408  0.222647 -0.165829  0.240792 -0.016109   \n",
       "batchfile         -0.141777 -0.151423 -0.054517  0.005919  0.201677 -0.182279   \n",
       "batch             -0.134676 -0.151257 -0.063340  0.014618  0.209485 -0.174544   \n",
       "tags              -0.079021 -0.182590 -0.011616 -0.117084 -0.089697  0.117846   \n",
       "windowsserver2003 -0.106000 -0.163610  0.006828  0.196599 -0.124634  0.102909   \n",
       "2003              -0.088174 -0.162152  0.027191  0.215464 -0.146168  0.129161   \n",
       "projectmanagement  0.064704  0.089723 -0.020307 -0.222443  0.151793  0.002323   \n",
       "project            0.057824  0.087352 -0.023723 -0.230598  0.147870  0.000239   \n",
       "management         0.069184  0.083498 -0.014385 -0.222648  0.139799  0.004829   \n",
       "django            -0.179043 -0.228200 -0.196501  0.089277  0.044212 -0.134909   \n",
       "xcode             -0.431871 -0.236443 -0.431221 -0.119481  0.172691 -0.158620   \n",
       "ssis              -0.097085 -0.011572 -0.121647  0.280952  0.021820  0.095513   \n",
       "gcc                0.067722  0.172127 -0.070277 -0.133267  0.069797 -0.152909   \n",
       "googlechrome      -0.157474 -0.142357 -0.149643 -0.235564  0.170354 -0.260557   \n",
       "google            -0.162377 -0.146068 -0.140268 -0.236106  0.174301 -0.277694   \n",
       "chrome            -0.174793 -0.151426 -0.163680 -0.248325  0.183933 -0.279071   \n",
       "\n",
       "                   webservices     net35       web  services    ...     \\\n",
       "csharp                0.313661  0.472975  0.245507  0.292474    ...      \n",
       "winforms              0.138505  0.387025  0.049098  0.189758    ...      \n",
       "net                   0.408789  0.592367  0.280396  0.423699    ...      \n",
       "datetime             -0.085031 -0.151194  0.169922  0.058921    ...      \n",
       "math                 -0.096500 -0.316790 -0.126464 -0.099828    ...      \n",
       "linq                  0.222441  0.498243  0.186103  0.308208    ...      \n",
       "webservices           1.000000  0.235499  0.527316  0.614818    ...      \n",
       "net35                 0.235499  1.000000  0.142621  0.207576    ...      \n",
       "web                   0.527316  0.142621  1.000000  0.643264    ...      \n",
       "services              0.614818  0.207576  0.643264  1.000000    ...      \n",
       "3                     0.335846  0.852441  0.139067  0.242827    ...      \n",
       "5                     0.296228  0.972923  0.179181  0.205237    ...      \n",
       "database             -0.109869 -0.096438  0.016673  0.073720    ...      \n",
       "mysql                -0.198212 -0.314818 -0.002684 -0.061339    ...      \n",
       "performance           0.006912  0.147599  0.143067  0.040876    ...      \n",
       "unix                  0.044687 -0.199405  0.049449 -0.017235    ...      \n",
       "algorithm            -0.086614 -0.100914 -0.096739 -0.187645    ...      \n",
       "languageagnostic      0.061578 -0.114958  0.062185 -0.171770    ...      \n",
       "language             -0.084156 -0.020723  0.064047 -0.195430    ...      \n",
       "agnostic             -0.046875 -0.140409 -0.029183 -0.237268    ...      \n",
       "triggers             -0.242308 -0.342695 -0.023795 -0.051219    ...      \n",
       "sockets               0.005493 -0.171751 -0.015419 -0.128116    ...      \n",
       "c++                  -0.028536 -0.143943 -0.093068 -0.108870    ...      \n",
       "c                    -0.180828 -0.236815 -0.172127 -0.229798    ...      \n",
       "flex                  0.285539  0.239302  0.151466  0.175666    ...      \n",
       "actionscript3         0.172374  0.393485 -0.069899  0.056514    ...      \n",
       "arrays               -0.012647  0.061095  0.036728 -0.028075    ...      \n",
       "actionscript          0.156750  0.432757 -0.070065  0.045435    ...      \n",
       "sqlserver             0.024368 -0.047220  0.042341  0.132320    ...      \n",
       "sql                  -0.020789 -0.054950  0.016241  0.161121    ...      \n",
       "...                        ...       ...       ...       ...    ...      \n",
       "coding               -0.118463  0.045395 -0.048561 -0.108131    ...      \n",
       "style                -0.087930  0.062477 -0.007767 -0.085483    ...      \n",
       "api                   0.269012 -0.072742  0.320752  0.286330    ...      \n",
       "moss                  0.237179 -0.192632 -0.022667  0.106722    ...      \n",
       "net20                 0.126023  0.459659  0.090172  0.111089    ...      \n",
       "2                     0.139752  0.454970  0.106617  0.139992    ...      \n",
       "0                     0.121356  0.473118  0.083446  0.110834    ...      \n",
       "windowsinstaller      0.095150  0.258570  0.037811  0.207771    ...      \n",
       "json                  0.326873  0.090944  0.293087  0.315278    ...      \n",
       "inheritance           0.079810  0.135582  0.006365  0.151842    ...      \n",
       "serialization         0.298384  0.279857  0.268799  0.337641    ...      \n",
       "jsp                  -0.056436 -0.133205  0.058064 -0.155754    ...      \n",
       "resources             0.174354  0.013601  0.270211  0.094857    ...      \n",
       "soap                  0.592132  0.076167  0.608768  0.564711    ...      \n",
       "nant                  0.066400  0.092709 -0.137668  0.096626    ...      \n",
       "batchfile            -0.101915 -0.320197 -0.083162  0.056249    ...      \n",
       "batch                -0.089051 -0.322183 -0.061567  0.066377    ...      \n",
       "tags                  0.000147  0.209454 -0.253122 -0.075897    ...      \n",
       "windowsserver2003     0.081118 -0.125862  0.161934  0.174298    ...      \n",
       "2003                  0.085192 -0.099412  0.158545  0.177771    ...      \n",
       "projectmanagement    -0.010690  0.013630 -0.199889  0.015992    ...      \n",
       "project              -0.025874  0.000043 -0.214108  0.001959    ...      \n",
       "management           -0.005767  0.014790 -0.194130  0.023857    ...      \n",
       "django               -0.107428 -0.299642 -0.035843 -0.147855    ...      \n",
       "xcode                -0.388371 -0.221236 -0.375200 -0.316838    ...      \n",
       "ssis                 -0.153298 -0.232364 -0.111232  0.055615    ...      \n",
       "gcc                  -0.042258 -0.007241  0.027515  0.005984    ...      \n",
       "googlechrome         -0.068114 -0.148847  0.062164 -0.047056    ...      \n",
       "google               -0.059132 -0.143669  0.059372 -0.057971    ...      \n",
       "chrome               -0.080950 -0.163694  0.043919 -0.065465    ...      \n",
       "\n",
       "                   projectmanagement   project  management    django  \\\n",
       "csharp                      0.064704  0.057824    0.069184 -0.179043   \n",
       "winforms                    0.089723  0.087352    0.083498 -0.228200   \n",
       "net                        -0.020307 -0.023723   -0.014385 -0.196501   \n",
       "datetime                   -0.222443 -0.230598   -0.222648  0.089277   \n",
       "math                        0.151793  0.147870    0.139799  0.044212   \n",
       "linq                        0.002323  0.000239    0.004829 -0.134909   \n",
       "webservices                -0.010690 -0.025874   -0.005767 -0.107428   \n",
       "net35                       0.013630  0.000043    0.014790 -0.299642   \n",
       "web                        -0.199889 -0.214108   -0.194130 -0.035843   \n",
       "services                    0.015992  0.001959    0.023857 -0.147855   \n",
       "3                           0.057981  0.055265    0.060874 -0.322312   \n",
       "5                           0.035886  0.022609    0.036821 -0.302099   \n",
       "database                   -0.087232 -0.043525   -0.084179  0.398257   \n",
       "mysql                      -0.141750 -0.112594   -0.138778  0.429127   \n",
       "performance                -0.351383 -0.358005   -0.364200 -0.052039   \n",
       "unix                       -0.032546 -0.065737   -0.061929 -0.164504   \n",
       "algorithm                   0.103851  0.113464    0.084675  0.151176   \n",
       "languageagnostic           -0.076114 -0.061300   -0.086680  0.201462   \n",
       "language                   -0.009668 -0.001610   -0.013701  0.131696   \n",
       "agnostic                   -0.082549 -0.070377   -0.090565  0.216714   \n",
       "triggers                    0.077929  0.106627    0.073104  0.287620   \n",
       "sockets                    -0.094771 -0.109072   -0.106859 -0.023662   \n",
       "c++                         0.086566  0.068943    0.066483 -0.016346   \n",
       "c                           0.118058  0.100393    0.100807 -0.017167   \n",
       "flex                       -0.021724 -0.034478   -0.017484 -0.132346   \n",
       "actionscript3               0.154007  0.150334    0.163391 -0.157322   \n",
       "arrays                      0.077623  0.064391    0.082148  0.008736   \n",
       "actionscript                0.149259  0.142773    0.159560 -0.175708   \n",
       "sqlserver                   0.056055  0.060797    0.053712  0.160027   \n",
       "sql                        -0.021585 -0.011987   -0.027456  0.048622   \n",
       "...                              ...       ...         ...       ...   \n",
       "coding                      0.079709  0.083076    0.068159  0.084486   \n",
       "style                       0.056898  0.060870    0.045690  0.100293   \n",
       "api                        -0.007164 -0.001174   -0.008269  0.086117   \n",
       "moss                        0.235750  0.236153    0.231446  0.003330   \n",
       "net20                       0.200273  0.185696    0.212731 -0.196490   \n",
       "2                           0.170690  0.157563    0.184812 -0.191904   \n",
       "0                           0.177952  0.163073    0.190531 -0.207649   \n",
       "windowsinstaller            0.162502  0.145773    0.166024 -0.020578   \n",
       "json                        0.013807  0.003738    0.026071 -0.189280   \n",
       "inheritance                 0.235528  0.236972    0.232096  0.149753   \n",
       "serialization               0.152579  0.144334    0.158567 -0.123071   \n",
       "jsp                         0.120055  0.126537    0.111213 -0.073672   \n",
       "resources                   0.090069  0.100499    0.076287  0.140621   \n",
       "soap                        0.115448  0.090085    0.113052 -0.005761   \n",
       "nant                        0.364177  0.367304    0.360375  0.045630   \n",
       "batchfile                   0.293778  0.274961    0.287831 -0.021488   \n",
       "batch                       0.305354  0.285785    0.299454 -0.008061   \n",
       "tags                        0.269712  0.300414    0.271070  0.154371   \n",
       "windowsserver2003           0.031206  0.022140    0.035362  0.086966   \n",
       "2003                        0.015330  0.007859    0.020160  0.093479   \n",
       "projectmanagement           1.000000  0.996407    0.998218  0.166261   \n",
       "project                     0.996407  1.000000    0.996428  0.199910   \n",
       "management                  0.998218  0.996428    1.000000  0.173060   \n",
       "django                      0.166261  0.199910    0.173060  1.000000   \n",
       "xcode                       0.138688  0.135342    0.132103  0.134412   \n",
       "ssis                        0.147594  0.137102    0.145151  0.044895   \n",
       "gcc                        -0.009999 -0.013917   -0.023064 -0.053504   \n",
       "googlechrome                0.146735  0.154459    0.136170  0.137268   \n",
       "google                      0.154205  0.160906    0.141577  0.121730   \n",
       "chrome                      0.169721  0.177629    0.157411  0.135096   \n",
       "\n",
       "                      xcode      ssis       gcc  googlechrome    google  \\\n",
       "csharp            -0.431871 -0.097085  0.067722     -0.157474 -0.162377   \n",
       "winforms          -0.236443 -0.011572  0.172127     -0.142357 -0.146068   \n",
       "net               -0.431221 -0.121647 -0.070277     -0.149643 -0.140268   \n",
       "datetime          -0.119481  0.280952 -0.133267     -0.235564 -0.236106   \n",
       "math               0.172691  0.021820  0.069797      0.170354  0.174301   \n",
       "linq              -0.158620  0.095513 -0.152909     -0.260557 -0.277694   \n",
       "webservices       -0.388371 -0.153298 -0.042258     -0.068114 -0.059132   \n",
       "net35             -0.221236 -0.232364 -0.007241     -0.148847 -0.143669   \n",
       "web               -0.375200 -0.111232  0.027515      0.062164  0.059372   \n",
       "services          -0.316838  0.055615  0.005984     -0.047056 -0.057971   \n",
       "3                 -0.415422 -0.225073  0.002802     -0.013205 -0.000993   \n",
       "5                 -0.248059 -0.221808  0.010707     -0.212923 -0.206192   \n",
       "database           0.219522  0.113575 -0.007699     -0.043280 -0.062990   \n",
       "mysql              0.094437  0.261517  0.207747     -0.037779 -0.037238   \n",
       "performance       -0.147571 -0.058325  0.328773     -0.204776 -0.197326   \n",
       "unix              -0.008220  0.092619  0.344720      0.134415  0.170218   \n",
       "algorithm         -0.064551 -0.011091  0.200006      0.028652  0.060048   \n",
       "languageagnostic   0.044288 -0.136653  0.121310      0.027422  0.050939   \n",
       "language           0.116051 -0.053588  0.176025      0.140256  0.149504   \n",
       "agnostic           0.094534 -0.076919  0.112624      0.069040  0.086433   \n",
       "triggers           0.186824  0.415866  0.041727      0.215826  0.221336   \n",
       "sockets           -0.062941 -0.061278  0.150240     -0.058825 -0.072482   \n",
       "c++                0.021770 -0.054775  0.730737      0.110222  0.124397   \n",
       "c                  0.375247  0.010328  0.629540      0.099498  0.110758   \n",
       "flex               0.025377  0.002691  0.046081      0.077450  0.092466   \n",
       "actionscript3      0.046678 -0.020416  0.090894      0.073811  0.090310   \n",
       "arrays            -0.150350 -0.129818  0.147037     -0.079557 -0.074525   \n",
       "actionscript       0.078958 -0.031844  0.085649      0.040626  0.056363   \n",
       "sqlserver         -0.023467  0.526679 -0.085275     -0.090599 -0.096311   \n",
       "sql                0.101988  0.663381  0.024642     -0.177375 -0.184730   \n",
       "...                     ...       ...       ...           ...       ...   \n",
       "coding             0.012269 -0.152478  0.016733     -0.076554 -0.064880   \n",
       "style             -0.001036 -0.165329  0.017653     -0.107061 -0.096082   \n",
       "api               -0.243281 -0.099902  0.396984      0.278039  0.255137   \n",
       "moss               0.281899  0.311607  0.066676      0.252141  0.258608   \n",
       "net20             -0.015053 -0.120237 -0.102719     -0.135580 -0.132775   \n",
       "2                  0.008637 -0.109617 -0.092510     -0.138529 -0.137728   \n",
       "0                  0.000351 -0.142727 -0.063141     -0.133769 -0.132652   \n",
       "windowsinstaller   0.004350  0.254620  0.111356     -0.006278 -0.022072   \n",
       "json              -0.193708 -0.015870 -0.092641      0.088857  0.102987   \n",
       "inheritance        0.016881 -0.072459 -0.085527     -0.091094 -0.123479   \n",
       "serialization     -0.273647 -0.039342 -0.265844     -0.061390 -0.065664   \n",
       "jsp                0.006219 -0.084378 -0.046971      0.070350  0.070101   \n",
       "resources         -0.063307 -0.356239  0.229920      0.482836  0.510663   \n",
       "soap              -0.211802 -0.166253  0.132897      0.119036  0.112160   \n",
       "nant               0.051802 -0.225887  0.049047      0.278747  0.285547   \n",
       "batchfile          0.204622  0.507181 -0.023083      0.118395  0.106525   \n",
       "batch              0.202259  0.505762 -0.005841      0.128364  0.116189   \n",
       "tags               0.129830 -0.028662 -0.131404      0.124113  0.137976   \n",
       "windowsserver2003  0.102762  0.552346 -0.308065     -0.035594 -0.057088   \n",
       "2003               0.075214  0.562166 -0.318498     -0.076830 -0.096891   \n",
       "projectmanagement  0.138688  0.147594 -0.009999      0.146735  0.154205   \n",
       "project            0.135342  0.137102 -0.013917      0.154459  0.160906   \n",
       "management         0.132103  0.145151 -0.023064      0.136170  0.141577   \n",
       "django             0.134412  0.044895 -0.053504      0.137268  0.121730   \n",
       "xcode              1.000000  0.194005  0.094029      0.102121  0.087101   \n",
       "ssis               0.194005  1.000000 -0.063756     -0.105655 -0.115650   \n",
       "gcc                0.094029 -0.063756  1.000000      0.176159  0.184379   \n",
       "googlechrome       0.102121 -0.105655  0.176159      1.000000  0.994905   \n",
       "google             0.087101 -0.115650  0.184379      0.994905  1.000000   \n",
       "chrome             0.105748 -0.113854  0.195592      0.994979  0.997540   \n",
       "\n",
       "                     chrome  \n",
       "csharp            -0.174793  \n",
       "winforms          -0.151426  \n",
       "net               -0.163680  \n",
       "datetime          -0.248325  \n",
       "math               0.183933  \n",
       "linq              -0.279071  \n",
       "webservices       -0.080950  \n",
       "net35             -0.163694  \n",
       "web                0.043919  \n",
       "services          -0.065465  \n",
       "3                 -0.013048  \n",
       "5                 -0.226366  \n",
       "database          -0.043515  \n",
       "mysql             -0.021818  \n",
       "performance       -0.199742  \n",
       "unix               0.156534  \n",
       "algorithm          0.062942  \n",
       "languageagnostic   0.051593  \n",
       "language           0.152430  \n",
       "agnostic           0.089676  \n",
       "triggers           0.240440  \n",
       "sockets           -0.068579  \n",
       "c++                0.136864  \n",
       "c                  0.134397  \n",
       "flex               0.075946  \n",
       "actionscript3      0.085023  \n",
       "arrays            -0.065675  \n",
       "actionscript       0.049357  \n",
       "sqlserver         -0.092245  \n",
       "sql               -0.176295  \n",
       "...                     ...  \n",
       "coding            -0.055179  \n",
       "style             -0.087191  \n",
       "api                0.258314  \n",
       "moss               0.247590  \n",
       "net20             -0.144445  \n",
       "2                 -0.150778  \n",
       "0                 -0.143530  \n",
       "windowsinstaller  -0.030307  \n",
       "json               0.094430  \n",
       "inheritance       -0.110172  \n",
       "serialization     -0.072423  \n",
       "jsp                0.082928  \n",
       "resources          0.518664  \n",
       "soap               0.108715  \n",
       "nant               0.277354  \n",
       "batchfile          0.107558  \n",
       "batch              0.117439  \n",
       "tags               0.153077  \n",
       "windowsserver2003 -0.071822  \n",
       "2003              -0.112374  \n",
       "projectmanagement  0.169721  \n",
       "project            0.177629  \n",
       "management         0.157411  \n",
       "django             0.135096  \n",
       "xcode              0.105748  \n",
       "ssis              -0.113854  \n",
       "gcc                0.195592  \n",
       "googlechrome       0.994979  \n",
       "google             0.997540  \n",
       "chrome             1.000000  \n",
       "\n",
       "[351 rows x 351 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting the pure tags similarity matrix\")\n",
    "L_word2vec_pure_tags_words = [word for word in pure_tags_vectors.vocab.keys()]\n",
    "\n",
    "df_word2vec_pure_tags_coordinates = pd.DataFrame(columns = [i for i in range(0,50)])\n",
    "for word in L_word2vec_pure_tags_words:\n",
    "    df_word_coordinates = pd.DataFrame(pure_tags_vectors[word]).T\n",
    "    df_word_coordinates.index = [word]\n",
    "    df_word2vec_pure_tags_coordinates = df_word2vec_pure_tags_coordinates.append(df_word_coordinates)\n",
    "\n",
    "X_pure_tags_word2vec = df_word2vec_pure_tags_coordinates.values\n",
    "\n",
    "df_word2vec_pure_tags_similarity = pd.DataFrame(cosine_similarity(X_pure_tags_word2vec),\\\n",
    "                                           columns=df_word2vec_pure_tags_coordinates.index,\\\n",
    "                                           index=df_word2vec_pure_tags_coordinates.index)\n",
    "df_word2vec_pure_tags_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.1539130210876465 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on the test data : Building the test datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction on the test data : Building the test datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_test_corpus = list(df_test['corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting count features for NMF...\n",
      "--- 0.05285215377807617 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting count features for NMF...\")\n",
    "test_tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=10, max_features=N_FEATURES)\n",
    "\n",
    "start_time = time.time()\n",
    "test_tfidf = test_tfidf_vectorizer.fit_transform(L_test_corpus)\n",
    "test_vectorizer_feature_names = test_tfidf_vectorizer.get_feature_names()\n",
    "test_tfidf_array = test_tfidf.toarray()\n",
    "df_all_test_words_nmf = pd.DataFrame(test_tfidf_array, columns=test_vectorizer_feature_names)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting count features for lda...\n",
      "--- 0.0498659610748291 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting count features for lda...\")\n",
    "test_tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=10, max_features=N_FEATURES)\n",
    "\n",
    "start_time = time.time()\n",
    "test_tfidf = test_tfidf_vectorizer.fit_transform(L_test_corpus)\n",
    "test_vectorizer_feature_names = test_tfidf_vectorizer.get_feature_names()\n",
    "test_tfidf_array = test_tfidf.toarray()\n",
    "df_all_test_words_lda = pd.DataFrame(test_tfidf_array, columns=test_vectorizer_feature_names)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get back the train columns schema :\n",
    "df_final_test_words = df_train_nmf_words_space_schema.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test space words dimension is 875\n",
      "After filtering on the train columns perimeter, test space words dimension is 795\n"
     ]
    }
   ],
   "source": [
    "#The original shape is :\n",
    "test_words_dim = df_all_test_words_nmf.shape[1]\n",
    "print(\"Original test space words dimension is %s\"%test_words_dim)\n",
    "#But we have to filter the data onto the train space perimeter\n",
    "df_all_test_words_nmf = df_all_test_words_nmf[[col for col in df_all_test_words_nmf.columns if col in list(df_final_test_words.columns)]]\n",
    "df_all_test_words_lda = df_all_test_words_lda[[col for col in df_all_test_words_lda.columns if col in list(df_final_test_words.columns)]]\n",
    "test_words_dim = df_all_test_words_nmf.shape[1]\n",
    "print(\"After filtering on the train columns perimeter, test space words dimension is %s\"%test_words_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Finally, the test data looks like : \n",
    "df_final_test_words_nmf = df_final_test_words.append(df_all_test_words_nmf)\n",
    "df_final_test_words_lda = df_final_test_words.append(df_all_test_words_lda)\n",
    "df_final_test_words_nmf.fillna(0, inplace=True)\n",
    "df_final_test_words_lda.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix_nmf = df_final_test_words_nmf.values\n",
    "test_matrix_lda = df_final_test_words_lda.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying NMF and LDA on the test data\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying NMF and LDA on the test data\")\n",
    "test_results_nmf = nmf.transform(test_matrix_nmf)\n",
    "test_results_lda = lda.transform(test_matrix_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the main topics\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting the main topics\")\n",
    "L_test_main_topics_nmf = []\n",
    "L_test_main_topics_lda = []\n",
    "for sub_result_nmf, sub_result_lda in zip(test_results_nmf, test_results_lda):\n",
    "    L_test_main_topics_nmf.append(np.argmax(sub_result_nmf))\n",
    "    L_test_main_topics_lda.append(np.argmax(sub_result_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_nmf_corpus_topics = pd.DataFrame(test_results_nmf)\n",
    "df_test_lda_corpus_topics = pd.DataFrame(test_results_lda)\n",
    "\n",
    "df_test_nmf_corpus_topics['id'] = list(df_test_nmf['id'])\n",
    "df_test_lda_corpus_topics['id'] = list(df_test_lda['id'])\n",
    "\n",
    "df_test_nmf_corpus_topics['main_topic'] = L_test_main_topics_nmf\n",
    "df_test_lda_corpus_topics['main_topic'] = L_test_main_topics_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_nmf = pd.merge(df_test_nmf,df_test_nmf_corpus_topics,how='left',on='id')\n",
    "df_test_lda = pd.merge(df_test_lda,df_test_lda_corpus_topics,how='left',on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags generation on the test perimeter\n"
     ]
    }
   ],
   "source": [
    "print(\"Tags generation on the test perimeter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_nmf['nmf_tags'] = df_test_nmf['main_topic'].apply(lambda x : dict_topics_tags_nmf[x])\n",
    "df_test_lda['lda_tags'] = df_test_lda['main_topic'].apply(lambda x : dict_topics_tags_lda[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating nmf recommended tags\n",
      "Multiprocessing\n",
      "Creating pool with 6 processes\n",
      "\n",
      "TASK ready\n",
      "results ready\n",
      "final_results ready\n",
      "appending sub lists :\n",
      "success\n",
      "--- 8.86453890800476 seconds ---\n",
      "the result file is available at : \n",
      " temp_files_path+\"L_recommended_tags.p\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating nmf recommended tags\")\n",
    "#We specify the excution params for  the python script responsible for the multiprocessing : \n",
    "execution_params = {'N_PROCS' : 6,\n",
    "                    'list_of_corpus':list(df_test_nmf['corpus']),\n",
    "                    'nmf_word_sim_matrix':df_nmf_words_similarity,\n",
    "                    'nmf_tag_sim_matrix':df_nmf_tags_similarity,\n",
    "                    'existing_tags':L_frequent_tags,\n",
    "                    'NEIGHBORS':NEIGHBORS,\n",
    "                    'recommendation_filter':list(df_test_nmf['nmf_tags']),\n",
    "                    'QUANTILE_THRESHOLD':QUANTILE_THRESHOLD,\n",
    "                   }\n",
    "#We dump our execution params :\n",
    "pickle.dump(execution_params,open(temp_files_path+\"execution_params.p\", \"wb\"))\n",
    "#And we run the script responsible for the tags generation on different process :  \n",
    "%run -i multiprocessing_generate_tags_nmf.py\n",
    "\n",
    "\n",
    "#Now we can load the result of the multiprocessing task : \n",
    "L_recommended_tags_nmf = pickle.load(open(temp_files_path+\"L_recommended_tags.p\", \"rb\" ))\n",
    "\n",
    "\n",
    "\n",
    "#And we can clean the temp files dir :\n",
    "import os\n",
    "from functions import class_my_files\n",
    "dict_extensions = class_my_files(temp_files_path)\n",
    "pickles_temp_files  = dict_extensions['p']\n",
    "for file_name in pickles_temp_files:\n",
    "    os.remove(temp_files_path+file_name)\n",
    "\n",
    "#And we assign the result of the multiprocessing :\n",
    "df_test_nmf['recommendation_nmf'] = L_recommended_tags_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating lda recommended tags\n",
      "OK\n",
      "OK\n",
      "Multiprocessing\n",
      "Creating pool with 6 processes\n",
      "\n",
      "TASK ready\n",
      "results ready\n",
      "final_results ready\n",
      "appending sub lists :\n",
      "success\n",
      "--- 2.619110584259033 seconds ---\n",
      "the result file is available at : \n",
      " temp_files_path+\"L_recommended_tags.p\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating lda recommended tags\")\n",
    "#We specify the excution params for  the python script responsible for the multiprocessing : \n",
    "execution_params = {'N_PROCS' : 6,\n",
    "                    'list_of_corpus':list(df_test_lda['corpus']),\n",
    "                    'lda_word_sim_matrix':df_lda_words_similarity,\n",
    "                    'lda_tag_sim_matrix':df_lda_tags_similarity,\n",
    "                    'existing_tags':L_frequent_tags,\n",
    "                    'NEIGHBORS':NEIGHBORS,\n",
    "                    'recommendation_filter':list(df_test_lda['lda_tags']),\n",
    "                    'QUANTILE_THRESHOLD':QUANTILE_THRESHOLD,\n",
    "                   }\n",
    "#We dump our execution params :\n",
    "pickle.dump(execution_params,open(temp_files_path+\"execution_params.p\", \"wb\"))\n",
    "#And we run the script responsible for the tags generation on different process :  \n",
    "%run -i multiprocessing_generate_tags_lda.py\n",
    "\n",
    "\n",
    "#Now we can load the result of the multiprocessing task : \n",
    "L_recommended_tags_lda = pickle.load(open(temp_files_path+\"L_recommended_tags.p\", \"rb\" ))\n",
    "\n",
    "\n",
    "\n",
    "#And we can clean the temp files dir :\n",
    "import os\n",
    "from functions import class_my_files\n",
    "dict_extensions = class_my_files(temp_files_path)\n",
    "pickles_temp_files  = dict_extensions['p']\n",
    "for file_name in pickles_temp_files:\n",
    "    os.remove(temp_files_path+file_name)\n",
    "\n",
    "#And we assign the result of the multiprocessing :\n",
    "df_test_lda['recommendation_lda'] = L_recommended_tags_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating lda+vord2vec recommended tags\n",
      "OK\n",
      "OK\n",
      "Multiprocessing\n",
      "Creating pool with 6 processes\n",
      "\n",
      "TASK ready\n",
      "results ready\n",
      "final_results ready\n",
      "appending sub lists :\n",
      "success\n",
      "--- 33.764545917510986 seconds ---\n",
      "the result file is available at : \n",
      " temp_files_path+\"L_recommended_tags.p\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating lda+vord2vec recommended tags\")\n",
    "\n",
    "df_test_lda_word2vec = df_test_lda.copy()\n",
    "\n",
    "#We specify the excution params for  the python script responsible for the multiprocessing : \n",
    "execution_params = {'N_PROCS' : 6,\n",
    "                    'list_of_corpus':list(df_test_lda_word2vec['corpus']),\n",
    "                    'lda_word_sim_matrix':df_lda_words_similarity,\n",
    "                    'lda_tag_sim_matrix':df_lda_tags_similarity,\n",
    "                    \n",
    "                    'w2v_word_sim_matrix':df_word2vec_words_similarity,\n",
    "                    'w2v_tag_sim_matrix':df_word2vec_tags_similarity,\n",
    "                    'w2v_pure_tag_sim_matrix':df_word2vec_pure_tags_similarity,\n",
    "                    \n",
    "                    'existing_tags':L_frequent_tags,\n",
    "                    'NEIGHBORS':NEIGHBORS,\n",
    "                    'recommendation_filter':list(df_test_lda_word2vec['lda_tags']),\n",
    "                    'QUANTILE_THRESHOLD':QUANTILE_THRESHOLD,\n",
    "                   }\n",
    "#We dump our execution params :\n",
    "pickle.dump(execution_params,open(temp_files_path+\"execution_params.p\", \"wb\"))\n",
    "#And we run the script responsible for the tags generation on different process :  \n",
    "%run -i multiprocessing_generate_tags_lda_word2vec.py\n",
    "\n",
    "\n",
    "#Now we can load the result of the multiprocessing task : \n",
    "L_recommended_tags_lda_word2vec = pickle.load(open(temp_files_path+\"L_recommended_tags.p\", \"rb\" ))\n",
    "\n",
    "\n",
    "\n",
    "#And we can clean the temp files dir :\n",
    "import os\n",
    "from functions import class_my_files\n",
    "dict_extensions = class_my_files(temp_files_path)\n",
    "pickles_temp_files  = dict_extensions['p']\n",
    "for file_name in pickles_temp_files:\n",
    "    os.remove(temp_files_path+file_name)\n",
    "\n",
    "#And we assign the result of the multiprocessing :\n",
    "df_test_lda_word2vec['recommendation_lda_w2v'] = L_recommended_tags_lda_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the test perimeter\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation on the test perimeter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_nmf['n_tags_recommended_nmf'] = df_test_nmf.apply(lambda x : len(x['recommendation_nmf']),axis=1)\n",
    "df_test_lda['n_tags_recommended_lda'] = df_test_lda.apply(lambda x : len(x['recommendation_lda']),axis=1)\n",
    "df_test_lda_word2vec['n_tags_recommended_lda_w2v'] = df_test_lda_word2vec.apply(lambda x : len(x['recommendation_lda_w2v']),axis=1)\n",
    "\n",
    "df_test_nmf['matching_tags_test_nmf'] = df_test_nmf.apply(lambda x : set(x['recommendation_nmf']).intersection(set(x['tag_list'])), axis=1)\n",
    "df_test_lda['matching_tags_test_lda'] = df_test_lda.apply(lambda x : set(x['recommendation_lda']).intersection(set(x['tag_list'])), axis=1)\n",
    "df_test_lda_word2vec['matching_tags_test_lda_w2v'] = df_test_lda_word2vec.apply(lambda x : set(x['recommendation_lda_w2v']).intersection(set(x['tag_list'])), axis=1)\n",
    "\n",
    "df_test_nmf['matching_score_test_nmf'] = df_test_nmf.apply(lambda x : len(x['matching_tags_test_nmf'])/x['n_tags'], axis=1)\n",
    "df_test_lda['matching_score_test_lda'] = df_test_lda.apply(lambda x : len(x['matching_tags_test_lda'])/x['n_tags'], axis=1)\n",
    "df_test_lda_word2vec['matching_score_test_lda_w2v'] = df_test_lda_word2vec.apply(lambda x : len(x['matching_tags_test_lda_w2v'])/x['n_tags'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_tags</th>\n",
       "      <th>matching_score</th>\n",
       "      <th>n_tags_recommended_nmf</th>\n",
       "      <th>matching_score_test_nmf</th>\n",
       "      <th>n_tags_recommended_lda</th>\n",
       "      <th>matching_score_test_lda</th>\n",
       "      <th>n_tags_recommended_lda_w2v</th>\n",
       "      <th>matching_score_test_lda_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>16</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>148</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>16</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>5397</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>5400</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>5402</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>5411</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>5414</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>5415</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>5419</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>5422</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>5426</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>5435</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>5436</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>5444</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>5450</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>5451</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>5452</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>5454</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>5468</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>5469</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>15</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>5478</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>5479</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>5481</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>5483</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>5485</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>5487</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>5493</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>5497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>5504</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>5510</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>5517</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>5521</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1325 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  n_tags  matching_score  n_tags_recommended_nmf  \\\n",
       "0        1       3        0.333333                       3   \n",
       "1        4       3        0.000000                       6   \n",
       "2       14       3        0.666667                       9   \n",
       "3       44       2        0.500000                       8   \n",
       "4       45       1        1.000000                      27   \n",
       "5       47       3        1.000000                      10   \n",
       "6       52       2        0.000000                       3   \n",
       "7       55       2        0.500000                      12   \n",
       "8       59       1        1.000000                       4   \n",
       "9       65       3        0.000000                       7   \n",
       "10      67       2        0.500000                       2   \n",
       "11      69       4        0.750000                      18   \n",
       "12      90       4        0.500000                       8   \n",
       "13      91       2        0.500000                      11   \n",
       "14      92       3        0.333333                       9   \n",
       "15      99       1        0.000000                       3   \n",
       "16     107       2        0.500000                      13   \n",
       "17     111       2        0.500000                       2   \n",
       "18     112       3        0.000000                       8   \n",
       "19     114       2        1.000000                       5   \n",
       "20     120       4        0.500000                       5   \n",
       "21     126       2        0.000000                       1   \n",
       "22     128       5        0.600000                      13   \n",
       "23     129       1        1.000000                       3   \n",
       "24     134       1        1.000000                       8   \n",
       "25     144       3        0.666667                       5   \n",
       "26     148       4        0.750000                       9   \n",
       "27     153       3        0.333333                      16   \n",
       "28     160       1        0.000000                       7   \n",
       "29     162       2        0.500000                       8   \n",
       "...    ...     ...             ...                     ...   \n",
       "1295  5397       1        0.000000                       7   \n",
       "1296  5400       2        1.000000                       8   \n",
       "1297  5402       1        1.000000                       6   \n",
       "1298  5411       2        1.000000                      14   \n",
       "1299  5414       1        0.000000                       5   \n",
       "1300  5415       3        0.666667                      10   \n",
       "1301  5419       2        1.000000                       5   \n",
       "1302  5422       2        0.000000                      14   \n",
       "1303  5426       2        1.000000                      11   \n",
       "1304  5435       2        1.000000                      12   \n",
       "1305  5436       2        1.000000                       7   \n",
       "1306  5444       2        0.500000                       5   \n",
       "1307  5450       1        0.000000                      14   \n",
       "1308  5451       3        0.000000                       2   \n",
       "1309  5452       3        0.000000                       2   \n",
       "1310  5454       1        1.000000                      22   \n",
       "1311  5468       2        1.000000                       7   \n",
       "1312  5469       3        0.666667                      10   \n",
       "1313  5478       2        0.500000                       6   \n",
       "1314  5479       2        0.500000                       5   \n",
       "1315  5481       2        1.000000                       6   \n",
       "1316  5483       2        0.500000                       4   \n",
       "1317  5485       3        0.333333                       4   \n",
       "1318  5487       2        0.000000                       3   \n",
       "1319  5493       3        0.000000                      11   \n",
       "1320  5497       1        0.000000                       8   \n",
       "1321  5504       2        0.500000                       8   \n",
       "1322  5510       1        1.000000                       7   \n",
       "1323  5517       3        0.333333                       8   \n",
       "1324  5521       1        0.000000                       3   \n",
       "\n",
       "      matching_score_test_nmf  n_tags_recommended_lda  \\\n",
       "0                    0.333333                       5   \n",
       "1                    0.000000                       7   \n",
       "2                    0.666667                      11   \n",
       "3                    0.500000                       7   \n",
       "4                    1.000000                      13   \n",
       "5                    1.000000                       9   \n",
       "6                    0.000000                       6   \n",
       "7                    0.500000                      10   \n",
       "8                    1.000000                       6   \n",
       "9                    0.000000                       4   \n",
       "10                   0.500000                       6   \n",
       "11                   0.750000                      16   \n",
       "12                   0.500000                      17   \n",
       "13                   0.500000                      11   \n",
       "14                   0.666667                       1   \n",
       "15                   0.000000                       1   \n",
       "16                   1.000000                       6   \n",
       "17                   0.500000                       7   \n",
       "18                   0.666667                       6   \n",
       "19                   1.000000                       2   \n",
       "20                   0.500000                       3   \n",
       "21                   0.000000                       0   \n",
       "22                   0.600000                      12   \n",
       "23                   1.000000                       4   \n",
       "24                   1.000000                       8   \n",
       "25                   0.666667                       6   \n",
       "26                   0.750000                       8   \n",
       "27                   0.666667                       8   \n",
       "28                   1.000000                       7   \n",
       "29                   0.500000                       4   \n",
       "...                       ...                     ...   \n",
       "1295                 0.000000                       7   \n",
       "1296                 1.000000                       9   \n",
       "1297                 1.000000                       7   \n",
       "1298                 1.000000                      16   \n",
       "1299                 0.000000                      11   \n",
       "1300                 0.666667                       8   \n",
       "1301                 1.000000                       8   \n",
       "1302                 0.500000                      10   \n",
       "1303                 1.000000                       9   \n",
       "1304                 1.000000                       6   \n",
       "1305                 1.000000                       6   \n",
       "1306                 0.500000                       4   \n",
       "1307                 0.000000                       8   \n",
       "1308                 0.000000                       0   \n",
       "1309                 0.000000                       6   \n",
       "1310                 1.000000                       7   \n",
       "1311                 1.000000                       4   \n",
       "1312                 0.666667                      10   \n",
       "1313                 0.500000                       9   \n",
       "1314                 0.500000                       5   \n",
       "1315                 1.000000                       7   \n",
       "1316                 0.500000                       5   \n",
       "1317                 0.666667                       6   \n",
       "1318                 0.000000                       4   \n",
       "1319                 0.000000                       9   \n",
       "1320                 0.000000                       9   \n",
       "1321                 1.000000                       3   \n",
       "1322                 1.000000                       9   \n",
       "1323                 0.333333                       8   \n",
       "1324                 0.000000                       6   \n",
       "\n",
       "      matching_score_test_lda  n_tags_recommended_lda_w2v  \\\n",
       "0                    0.666667                           6   \n",
       "1                    0.333333                           6   \n",
       "2                    0.666667                          16   \n",
       "3                    0.500000                           6   \n",
       "4                    1.000000                          11   \n",
       "5                    1.000000                          11   \n",
       "6                    0.000000                           4   \n",
       "7                    1.000000                          10   \n",
       "8                    1.000000                           8   \n",
       "9                    0.000000                           9   \n",
       "10                   0.500000                           4   \n",
       "11                   0.750000                          11   \n",
       "12                   0.500000                          15   \n",
       "13                   1.000000                          10   \n",
       "14                   0.333333                          10   \n",
       "15                   0.000000                           4   \n",
       "16                   0.500000                           8   \n",
       "17                   1.000000                           5   \n",
       "18                   0.333333                           8   \n",
       "19                   1.000000                           7   \n",
       "20                   0.500000                          10   \n",
       "21                   0.000000                           2   \n",
       "22                   0.600000                          18   \n",
       "23                   1.000000                           6   \n",
       "24                   1.000000                          13   \n",
       "25                   1.000000                           7   \n",
       "26                   0.750000                          11   \n",
       "27                   0.333333                          11   \n",
       "28                   0.000000                           6   \n",
       "29                   0.500000                           7   \n",
       "...                       ...                         ...   \n",
       "1295                 0.000000                           7   \n",
       "1296                 1.000000                           9   \n",
       "1297                 1.000000                           6   \n",
       "1298                 1.000000                          12   \n",
       "1299                 0.000000                          14   \n",
       "1300                 0.666667                          13   \n",
       "1301                 1.000000                           9   \n",
       "1302                 0.000000                          11   \n",
       "1303                 1.000000                           7   \n",
       "1304                 1.000000                           9   \n",
       "1305                 1.000000                           7   \n",
       "1306                 0.500000                           9   \n",
       "1307                 0.000000                           6   \n",
       "1308                 0.000000                           5   \n",
       "1309                 0.000000                           9   \n",
       "1310                 1.000000                           8   \n",
       "1311                 1.000000                           5   \n",
       "1312                 0.666667                          15   \n",
       "1313                 0.500000                          15   \n",
       "1314                 0.500000                           8   \n",
       "1315                 1.000000                           8   \n",
       "1316                 1.000000                           3   \n",
       "1317                 0.333333                           4   \n",
       "1318                 0.000000                           4   \n",
       "1319                 0.000000                          13   \n",
       "1320                 0.000000                          10   \n",
       "1321                 0.500000                           7   \n",
       "1322                 1.000000                          13   \n",
       "1323                 0.333333                           8   \n",
       "1324                 0.000000                           8   \n",
       "\n",
       "      matching_score_test_lda_w2v  \n",
       "0                        0.666667  \n",
       "1                        0.000000  \n",
       "2                        0.666667  \n",
       "3                        0.500000  \n",
       "4                        1.000000  \n",
       "5                        1.000000  \n",
       "6                        0.000000  \n",
       "7                        0.500000  \n",
       "8                        1.000000  \n",
       "9                        0.666667  \n",
       "10                       1.000000  \n",
       "11                       0.750000  \n",
       "12                       0.750000  \n",
       "13                       1.000000  \n",
       "14                       0.333333  \n",
       "15                       1.000000  \n",
       "16                       1.000000  \n",
       "17                       1.000000  \n",
       "18                       0.333333  \n",
       "19                       1.000000  \n",
       "20                       1.000000  \n",
       "21                       0.000000  \n",
       "22                       0.600000  \n",
       "23                       1.000000  \n",
       "24                       1.000000  \n",
       "25                       1.000000  \n",
       "26                       0.750000  \n",
       "27                       1.000000  \n",
       "28                       0.000000  \n",
       "29                       0.500000  \n",
       "...                           ...  \n",
       "1295                     1.000000  \n",
       "1296                     1.000000  \n",
       "1297                     1.000000  \n",
       "1298                     1.000000  \n",
       "1299                     0.000000  \n",
       "1300                     1.000000  \n",
       "1301                     1.000000  \n",
       "1302                     0.000000  \n",
       "1303                     1.000000  \n",
       "1304                     1.000000  \n",
       "1305                     1.000000  \n",
       "1306                     1.000000  \n",
       "1307                     0.000000  \n",
       "1308                     0.000000  \n",
       "1309                     0.000000  \n",
       "1310                     1.000000  \n",
       "1311                     1.000000  \n",
       "1312                     0.666667  \n",
       "1313                     0.500000  \n",
       "1314                     1.000000  \n",
       "1315                     1.000000  \n",
       "1316                     0.500000  \n",
       "1317                     0.333333  \n",
       "1318                     0.000000  \n",
       "1319                     0.000000  \n",
       "1320                     1.000000  \n",
       "1321                     0.500000  \n",
       "1322                     1.000000  \n",
       "1323                     0.333333  \n",
       "1324                     0.000000  \n",
       "\n",
       "[1325 rows x 9 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation = df_test.copy()\n",
    "df_evaluation = df_evaluation[['id','n_tags','matching_score']]\n",
    "df_evaluation = pd.merge(df_evaluation,df_test_nmf[['id','n_tags_recommended_nmf','matching_score_test_nmf']]\\\n",
    "                         ,how='left'\\\n",
    "                         ,on='id')\n",
    "\n",
    "df_evaluation = pd.merge(df_evaluation,df_test_lda[['id','n_tags_recommended_lda','matching_score_test_lda']]\\\n",
    "                         ,how='left'\\\n",
    "                         ,on='id')\n",
    "\n",
    "df_evaluation = pd.merge(df_evaluation,df_test_lda_word2vec[['id','n_tags_recommended_lda_w2v','matching_score_test_lda_w2v']]\\\n",
    "                         ,how='left'\\\n",
    "                         ,on='id')\n",
    "df_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">II) Evaluation & Benchmark of the algorithms performances</font>**\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_evaluation['nmf_tags_number_accuracy'] = df_evaluation.apply(lambda x:\n",
    "                                                                math.exp((x['n_tags']-x['n_tags_recommended_nmf'])/x['n_tags_recommended_nmf'])\n",
    "                                                                if x['n_tags']< x['n_tags_recommended_nmf']\n",
    "                                                                else\n",
    "                                                                math.exp((x['n_tags_recommended_nmf']-x['n_tags'])/x['n_tags'])\n",
    "                                                                ,axis=1)\n",
    "\n",
    "df_evaluation['lda_tags_number_accuracy'] = df_evaluation.apply(lambda x:\n",
    "                                                                math.exp((x['n_tags']-x['n_tags_recommended_lda'])/x['n_tags_recommended_lda'])\n",
    "                                                                if x['n_tags']< x['n_tags_recommended_lda']\n",
    "                                                                else\n",
    "                                                                math.exp((x['n_tags_recommended_lda']-x['n_tags'])/x['n_tags'])\n",
    "                                                                ,axis=1)\n",
    "\n",
    "df_evaluation['lda_w2v_tags_number_accuracy'] = df_evaluation.apply(lambda x:\n",
    "                                                                math.exp((x['n_tags']-x['n_tags_recommended_lda_w2v'])/x['n_tags_recommended_lda_w2v'])\n",
    "                                                                if x['n_tags']< x['n_tags_recommended_lda_w2v']\n",
    "                                                                else\n",
    "                                                                math.exp((x['n_tags_recommended_lda_w2v']-x['n_tags'])/x['n_tags'])\n",
    "                                                                ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_avg_accuracy = np.mean(df_evaluation['matching_score'])\n",
    "nmf_avg_accuracy = np.mean(df_evaluation['matching_score_test_nmf'])\n",
    "lda_avg_accuracy = np.mean(df_evaluation['matching_score_test_lda'])\n",
    "lda_w2v_avg_accuracy = np.mean(df_evaluation['matching_score_test_lda_w2v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_avg_tags_number_accuracy = np.mean(df_evaluation['nmf_tags_number_accuracy'])\n",
    "lda_avg_tags_number_accuracy = np.mean(df_evaluation['lda_tags_number_accuracy'])\n",
    "lda_w2v_avg_tags_number_accuracy = np.mean(df_evaluation['lda_w2v_tags_number_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_global_accuracy = (2*nmf_avg_accuracy+nmf_avg_tags_number_accuracy)/3\n",
    "lda_global_accuracy = (2*lda_avg_accuracy+lda_avg_tags_number_accuracy)/3\n",
    "lda_global_avg_accuracy = (2*lda_w2v_avg_accuracy+lda_w2v_avg_tags_number_accuracy)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_avg_accuracy : 0.53213836478\n",
      "nmf_avg_accuracy : 0.593610062893\n",
      "lda_avg_accuracy : 0.566503144654\n",
      "lda_w2v_avg_accuracy : 0.66841509434\n",
      "\n",
      "nmf_tags_number_accuracy : 0.528474936899\n",
      "lda_tags_number_accuracy : 0.517045074032\n",
      "lda_w2v_tags_number_accuracy : 0.504521133694\n",
      "\n",
      "nmf_global_accuracy : 0.571898354229\n",
      "lda_global_accuracy : 0.550017121114\n",
      "lda_global_avg_accuracy : 0.613783774124\n"
     ]
    }
   ],
   "source": [
    "print(\"orig_avg_accuracy : %s\"%orig_avg_accuracy)\n",
    "print(\"nmf_avg_accuracy : %s\"%nmf_avg_accuracy)\n",
    "print(\"lda_avg_accuracy : %s\"%lda_avg_accuracy)\n",
    "print(\"lda_w2v_avg_accuracy : %s\"%lda_w2v_avg_accuracy)\n",
    "\n",
    "print()\n",
    "print(\"nmf_avg_tags_number_accuracy : %s\"%nmf_avg_tags_number_accuracy)\n",
    "print(\"lda_avg_tags_number_accuracy : %s\"%lda_avg_tags_number_accuracy)\n",
    "print(\"lda_w2v_avg_tags_number_accuracy : %s\"%lda_w2v_avg_tags_number_accuracy)\n",
    "\n",
    "print()\n",
    "print(\"nmf_global_accuracy : %s\"%nmf_global_accuracy)\n",
    "print(\"lda_global_accuracy : %s\"%lda_global_accuracy)\n",
    "print(\"lda_global_avg_accuracy : %s\"%lda_global_avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_med_accuracy = np.mean(df_evaluation['matching_score'])\n",
    "nmf_med_accuracy = np.mean(df_evaluation['matching_score_test_nmf'])\n",
    "lda_med_accuracy = np.mean(df_evaluation['matching_score_test_lda'])\n",
    "lda_w2v_med_accuracy = np.mean(df_evaluation['matching_score_test_lda_w2v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_avg_tags_number = np.mean(df_evaluation['n_tags'])\n",
    "nmf_avg_tags_number = np.mean(df_evaluation['n_tags_recommended_nmf'])\n",
    "lda_avg_tags_number = np.mean(df_evaluation['n_tags_recommended_lda'])\n",
    "lda_w2v_avg_tags_number = np.mean(df_evaluation['n_tags_recommended_lda_w2v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_med_tags_number = np.median(df_evaluation['n_tags'])\n",
    "nmf_med_tags_number = np.median(df_evaluation['n_tags_recommended_nmf'])\n",
    "lda_med_tags_number = np.median(df_evaluation['n_tags_recommended_lda'])\n",
    "lda_w2v_med_tags_number = np.median(df_evaluation['n_tags_recommended_lda_w2v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = execution_params_workflows_iteration['RUN']\n",
    "N_COMPONENTS = execution_params_workflows_iteration['N_COMPONENTS']\n",
    "TOPICS_THRESHOLD = execution_params_workflows_iteration['TOPICS_THRESHOLD']\n",
    "NEIGHBORS = execution_params_workflows_iteration['NEIGHBORS']\n",
    "QUANTILE_THRESHOLD = execution_params_workflows_iteration['QUANTILE_THRESHOLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = {'RUN':RUN,\n",
    "                'N_COMPONENTS':N_COMPONENTS,\n",
    "                'TOPICS_THRESHOLD':TOPICS_THRESHOLD,\n",
    "                'NEIGHBORS':NEIGHBORS,\n",
    "                'QUANTILE_THRESHOLD':QUANTILE_THRESHOLD,\n",
    "                'orig_avg_accuracy':orig_avg_accuracy,\n",
    "                'nmf_avg_accuracy':nmf_avg_accuracy,\n",
    "                'lda_avg_accuracy':lda_avg_accuracy,\n",
    "                'lda_w2v_avg_accuracy':lda_w2v_avg_accuracy,\n",
    "                'nmf_avg_tags_number_accuracy':nmf_avg_tags_number_accuracy,\n",
    "                'lda_avg_tags_number_accuracy':lda_avg_tags_number_accuracy,\n",
    "                'lda_w2v_avg_tags_number_accuracy':lda_w2v_avg_tags_number_accuracy,\n",
    "                'nmf_global_accuracy':nmf_global_accuracy,\n",
    "                'lda_global_accuracy':lda_global_accuracy,\n",
    "                'lda_global_avg_accuracy':lda_global_avg_accuracy,\n",
    "                'orig_med_accuracy':orig_med_accuracy,\n",
    "                'nmf_med_accuracy':nmf_med_accuracy,\n",
    "                'lda_med_accuracy':lda_med_accuracy,\n",
    "                'lda_w2v_med_accuracy':lda_w2v_med_accuracy,\n",
    "                'orig_avg_tags_number':orig_avg_tags_number,\n",
    "                'nmf_avg_tags_number':nmf_avg_tags_number,\n",
    "                'lda_avg_tags_number':lda_avg_tags_number,\n",
    "                'lda_w2v_avg_tags_number':lda_w2v_avg_tags_number,\n",
    "                'orig_med_tags_number':orig_med_tags_number,\n",
    "                'nmf_med_tags_number':nmf_med_tags_number,\n",
    "                'lda_med_tags_number':lda_med_tags_number,\n",
    "                'lda_w2v_med_tags_number':lda_w2v_med_tags_number\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_columns = \\\n",
    "['RUN','N_COMPONENTS','TOPICS_THRESHOLD','NEIGHBORS','QUANTILE_THRESHOLD','orig_avg_accuracy','nmf_avg_accuracy',\\\n",
    " 'lda_avg_accuracy','lda_w2v_avg_accuracy','nmf_avg_tags_number_accuracy','lda_avg_tags_number_accuracy',\\\n",
    " 'lda_w2v_avg_tags_number_accuracy','nmf_global_accuracy','lda_global_accuracy','lda_global_avg_accuracy',\\\n",
    " 'orig_med_accuracy','nmf_med_accuracy','lda_med_accuracy','lda_w2v_med_accuracy','orig_avg_tags_number',\\\n",
    " 'nmf_avg_tags_number','lda_avg_tags_number','lda_w2v_avg_tags_number','orig_med_tags_number',\\\n",
    " 'nmf_med_tags_number','lda_med_tags_number','lda_w2v_med_tags_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_avg_accuracy</th>\n",
       "      <th>nmf_avg_accuracy</th>\n",
       "      <th>lda_avg_accuracy</th>\n",
       "      <th>lda_w2v_avg_accuracy</th>\n",
       "      <th>nmf_avg_tags_number_accuracy</th>\n",
       "      <th>lda_avg_tags_number_accuracy</th>\n",
       "      <th>lda_w2v_avg_tags_number_accuracy</th>\n",
       "      <th>nmf_global_accuracy</th>\n",
       "      <th>lda_global_accuracy</th>\n",
       "      <th>lda_global_avg_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>lda_med_accuracy</th>\n",
       "      <th>lda_w2v_med_accuracy</th>\n",
       "      <th>orig_avg_tags_number</th>\n",
       "      <th>nmf_avg_tags_number</th>\n",
       "      <th>lda_avg_tags_number</th>\n",
       "      <th>lda_w2v_tags_number</th>\n",
       "      <th>orig_med_tags_number</th>\n",
       "      <th>nmf_med_tags_number</th>\n",
       "      <th>lda_med_tags_number</th>\n",
       "      <th>lda_w2v_tags_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.532138</td>\n",
       "      <td>0.59361</td>\n",
       "      <td>0.566503</td>\n",
       "      <td>0.668415</td>\n",
       "      <td>0.528475</td>\n",
       "      <td>0.517045</td>\n",
       "      <td>0.504521</td>\n",
       "      <td>0.571898</td>\n",
       "      <td>0.550017</td>\n",
       "      <td>0.613784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566503</td>\n",
       "      <td>0.668415</td>\n",
       "      <td>2.119245</td>\n",
       "      <td>7.790189</td>\n",
       "      <td>7.038491</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   orig_avg_accuracy  nmf_avg_accuracy  lda_avg_accuracy  \\\n",
       "1           0.532138           0.59361          0.566503   \n",
       "\n",
       "   lda_w2v_avg_accuracy  nmf_avg_tags_number_accuracy  \\\n",
       "1              0.668415                      0.528475   \n",
       "\n",
       "   lda_avg_tags_number_accuracy  lda_w2v_avg_tags_number_accuracy  \\\n",
       "1                      0.517045                          0.504521   \n",
       "\n",
       "   nmf_global_accuracy  lda_global_accuracy  lda_global_avg_accuracy  \\\n",
       "1             0.571898             0.550017                 0.613784   \n",
       "\n",
       "          ...           lda_med_accuracy  lda_w2v_med_accuracy  \\\n",
       "1         ...                   0.566503              0.668415   \n",
       "\n",
       "   orig_avg_tags_number  nmf_avg_tags_number  lda_avg_tags_number  \\\n",
       "1              2.119245             7.790189             7.038491   \n",
       "\n",
       "   lda_w2v_tags_number  orig_med_tags_number  nmf_med_tags_number  \\\n",
       "1                  8.0                   2.0                  7.0   \n",
       "\n",
       "   lda_med_tags_number  lda_w2v_tags_number  \n",
       "1                  7.0                  8.0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(dict_results,columns = results_columns,index=[RUN])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results_df,open(pickles_path+\"1_workflows_iteration_results_df.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
